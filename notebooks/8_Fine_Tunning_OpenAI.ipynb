{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zKuIArGZkiD"
      },
      "source": [
        "# Fine Tuning Open Ai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT-mzHaZZpL9"
      },
      "source": [
        "## **1. Instalación de librerías y carga de dependencias**\n",
        "\n",
        "Se instalan las librerías esenciales:\n",
        "\n",
        "* **transformers** y **datasets** para trabajar con modelos avanzados de lenguaje natural y conjuntos de datos compatibles con HuggingFace.\n",
        "* **torch** para Deep Learning con PyTorch.\n",
        "* Se importan utilidades para entrenamiento, optimización, manejo de datos, y visualización.\n",
        "\n",
        "Esto permite trabajar tanto con modelos clásicos (entrenados localmente) como con APIs de modelos grandes (LLMs como GPT)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKiWIwOdf6LX",
        "outputId": "b871dadd-91c9-4f08-c37a-c5bad52b17cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVCxlHtGf50Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycX_f1pfZr8M"
      },
      "source": [
        "## **2. Carga de datos desde Google Drive**\n",
        "\n",
        "Se monta Google Drive y se definen las rutas a los archivos de entrenamiento y validación, cargando los DataFrames con pandas.\n",
        "Las columnas relevantes (`texto`, `etiqueta`) se normalizan y se crea una columna `label` necesaria para muchas APIs y formatos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds44eKJGejKN",
        "outputId": "cf355ab4-010e-4382-87b9-fffe0ec0b3c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMB1njp2gOCu"
      },
      "outputs": [],
      "source": [
        "#root_dir = \"/content/drive/MyDrive/aaa/\"\n",
        "#root_dir = r\"/content/drive/MyDrive/Proyecto-de-Grado-RAD-Alert/Oficial/Ahora-si-este-fue/data/\"\n",
        "root_dir = r\"/content/drive/MyDrive/PDG/data/\"\n",
        "\n",
        "path_df = root_dir + \"train_oversample_df.xlsx\"\n",
        "path_train = root_dir + \"train_oversample_df.xlsx\"\n",
        "path_test = root_dir + \"val_df.xlsx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6WxGzPVgTXj"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_excel(path_train)\n",
        "df_train[\"label\"] = df_train[\"etiqueta\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKIplkiNgTu5"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_excel(path_test)\n",
        "df_test[\"label\"] = df_test[\"etiqueta\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qVNWlPR3j1KS",
        "outputId": "3506fccb-ad03-4414-beca-507b027a169a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 3383,\n  \"fields\": [\n    {\n      \"column\": \"texto\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3383,\n        \"samples\": [\n          \"se observa traumatismo craneoencefalico moderado con signos de sangrado. no se evidencia hematoma subdural ni epidural. se identifica hemorragia subaracnoidea en la cisura silviana derecha y region basal anterior de ambos lobulos frontales. se observan contusiones hemorragicas frontales bilaterales, siendo la mayor de 18 x 12 mm en el lobulo frontal izquierdo. no se evidencia sangrado intraventricular. el parenquima cerebral muestra un aspecto general normal, sin presencia de edema, desviacion de la linea media, hernia o signos de isqu\",\n          \"control disminucion de la amplitud de los surcos y de las circunvoluciones por edema cerebral generalizado, diferenciacion sustancia blanca sustancia gris conservada. contusiones parenquimatosas temporales y frontales izquierdas en proceso de resolucion. cambios postquirurgicos de craneotomia pterional izquierda. tambien se observa cateter de derivacion ventricular que ingresa por el lobulo frontal izquierdo con su extremo distal localizado en el cuerpo del ventriculo lateral derecho. hay colapso del sistema ventricular supratentorial sin cambios significativos al comparar con estudio previo. linea media central. pequeno foco de sangrado subaracnoideo interhemisferico frontal adyacente a un foco de contusion. fosa posterior de apariencia escanografica normal. hematoma subgaleal biparietal de 15 mm. aumento en la densidad de la porcion distal del seno transverso derecho y seno sigmoideo ipsilateral, ya visualizado en estudio previo. diastasis de la sutura lambdoidea derecha con fractura longitudinal de la porcion mastoidea del hueso temporal y ocupacion por material con densidad tejidos blandos de las celdillas mastoideas y del oido medio. tambien se observa ocupacion de las celdillas mastoideas y oido medio del lado izquierdo. ocupacion por material hiperdenso, probablemente sangre, de los senos esfenoidales y engrosamiento mucoso algunas celdillas etmoidales posteriores. fracturas conocidas de las paredes del seno esfenoidal. orbitas de apariencia normal. aumento en la densidad de los senos transverso y derechos, ya visualizado en estudio previo edema cerebral generalizado. contusiones parenquimatosas temporales y frontales izquierdas sin cambios. fracturas en craneo ya conocidas y hemoseno esfenoidal.\",\n          \"sindrome febril. cambios post quirurgicos de craniotomia frontal derecha con derivacion ventricular que ingresa por esta region y cuyo extremo distal se encuentra en el cuerpo del ventriculo lateral izquierdo. sistema ventricular de tamano y morfologia normal sin edema transependimario. surcos y circunvoluciones simetricos. linea media central. adecuada diferenciacion de la sustancia blanca y gris. no colecciones epi o subdurales, signos de hemorragia subaracnoidea o parenquimatosa. iv ventriculo central, sin aparentes lesiones en fosa posterior evidentes a la escanografia. con las ventanas oseas no evidencia de fracturas. porcion visible de orbitas de aspecto normal. adecuada neumatizacion de mastoides y senos paranasales. adelgazamiento de la lamina cribosa manera bilateral y de predominio derecho sin imagenes sugestivas de encefalocele. engrosamiento mucoso en la fosa nasal derecha. cambios post quirurgicos de turbinectomia media y superior derecha, concha bullosa superior izquierda. cambios post quirurgicos de derivacion ventricular con cateter en adecuada posicion, no hay signos de actividad hidrocefalica. cambios post quirurgicos de correccion de encefalocele derecho.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"etiqueta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-62fd9f8a-81e7-4a16-9f1b-7a25664895ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>etiqueta</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cardiopatia compleja. surcos y circunvolucione...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>el paciente presenta un traumatismo craneoence...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cefalea surcos y circunvoluciones simetricos. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>se sospecha de un accidente cerebrovascular - ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>acv previo, trombocitopenia, anticoagulada con...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3378</th>\n",
              "      <td>desorientacion. prominencia de surcos y cisura...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3379</th>\n",
              "      <td>antecedente de tce: ahora confuso: a descartar...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3380</th>\n",
              "      <td>cefalea intensa en paciente anticoagulado. sur...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3381</th>\n",
              "      <td>cefalea. antecedente de hemorragia subaracnoid...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3382</th>\n",
              "      <td>hematoma subdural fronto-parietotemporal derec...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3383 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62fd9f8a-81e7-4a16-9f1b-7a25664895ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62fd9f8a-81e7-4a16-9f1b-7a25664895ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62fd9f8a-81e7-4a16-9f1b-7a25664895ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-65b73c92-e0b9-49c3-bf18-61064eb7a90b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-65b73c92-e0b9-49c3-bf18-61064eb7a90b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-65b73c92-e0b9-49c3-bf18-61064eb7a90b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ec56523d-0554-4d34-9c4a-a34d1b164079\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ec56523d-0554-4d34-9c4a-a34d1b164079 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                  texto  etiqueta  label\n",
              "0     cardiopatia compleja. surcos y circunvolucione...         0      0\n",
              "1     el paciente presenta un traumatismo craneoence...         1      1\n",
              "2     cefalea surcos y circunvoluciones simetricos. ...         0      0\n",
              "3     se sospecha de un accidente cerebrovascular - ...         1      1\n",
              "4     acv previo, trombocitopenia, anticoagulada con...         0      0\n",
              "...                                                 ...       ...    ...\n",
              "3378  desorientacion. prominencia de surcos y cisura...         0      0\n",
              "3379  antecedente de tce: ahora confuso: a descartar...         0      0\n",
              "3380  cefalea intensa en paciente anticoagulado. sur...         0      0\n",
              "3381  cefalea. antecedente de hemorragia subaracnoid...         0      0\n",
              "3382  hematoma subdural fronto-parietotemporal derec...         1      1\n",
              "\n",
              "[3383 rows x 3 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OXE4PC3Qj2dg",
        "outputId": "b6300c6e-6575-46a6-84cb-a75f7a30c415"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 659,\n  \"fields\": [\n    {\n      \"column\": \"texto\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 658,\n        \"samples\": [\n          \"control area malacica frontal izquierda. infarto lacunar en centro semioval izquierdo. focos hipodensos de distribucion difusa corticosubcortical y en la sustancia blanca periventricular, de caracter inespecifico, probablemente por leucoencefalopatia microangiopatica. prominencia de surcos y aumento del espacio subaracnoideo por perdida de volumen del parenquima cerebral. sistema ventricular de tamano, configuracion y densidad normales. linea media central. adecuada diferenciacion de la sustancia blanca y gris. no colecciones epi o subdurales, signos de hemorragia subaracnoidea o parenquimatosa. iv ventriculo central, sin aparentes lesiones en fosa posterior evidentes a la escanografia. con las ventanas oseas no evidencia de fracturas. porcion visible de orbitas de aspecto normal. adecuada neumatizacion de mastoides y senos paranasales. engrosamiento mucoso del compartimento izquierdo del seno esfenoidal. neumatizacion del apex petroso de manera bilateral. area de encefalomalacia frontal izquierda e infarto lacunar en el centro semioval ipsilateral. perdida de volumen del parenquima cerebral y leucoencefalopatia microangiopatica. estudio sin evidencia de procesos intracraneales agudos.\",\n          \"deterioro neurologico. reseccion de tumor cerebral el 15 de febrero de 2019. glioblastoma multiforme. cambios post quirurgicos de craneotomia frontoparietal izquierda por reseccion de tumor cerebral. en el lobulo frontal y parietal del lado izquierdo se identifica imagen hipodensa (14-16 uh) de morfologia irregular asociada con edema vasogenico y foco hiperdenso ovalado que corresponde ha sangrado agudo. ejerce efecto de masa con desviacion de 9 mm de la linea media hacia la derecha. hernia subfalcina y uncal izquierda. disminucion de surcos y espacio subaracnoideo por edema cerebral supratentorial difuso. obliteracion del ventriculo lateral izquierdo y dilatacion del asta occipital derecha. la morfologia cuarto ventriculo se encuentra conservada. iv ventriculo central, sin aparentes lesiones en fosa posterior evidentes a la escanografia. porcion visible de orbitas de aspecto normal. adecuada neumatizacion de mastoides y senos paranasales cambios post quirurgicos por reseccion de masa frontoparietal izquierda con presencia de lesion quistica asociada con edema vasogenico y foco de sangrado agudo. hernia subfalcial y uncal izquierdas. edema cerebral difuso.\",\n          \"trauma craneoencefalico signos de sangrado. hematoma subdural: no. hematoma epidural: no. hemorragia subaracnoidea: no. sangrado intraparenquimatoso: no. sangrado intraventricular: no. parenquima cerebral: aspecto general: normal. edema: no. desviacion de la linea media: no. hernia: no. signos de isquemia aguda: no. sistema ventricular: normal. cisternas basales: normales. cerebelo y fosa posterior: normales. tallo cerebral: normal. craneo: normal. base del craneo: normal. cara, senos paranasales, orbitas y mastoides: cambios por faquectomia bilateral. ocupacion por material con densidad de tejidos blandos y nivel hidroaereo en ambos senos maxilares. engrosamiento mucoso de algunas celdillas etmoidales anteriores y sin niveles hidroaereos. estructuras vasculares: calcificacion de los vasos del poligono. cambios por sinusopatia aguda maxilar bilateral. no se observa lesion isquemica o hemorragica intracraneal aguda, colecciones extraaxiales o lesiones expansivas.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"etiqueta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_test"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c1c93575-fffa-4f95-b3a7-b962e5cf72f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>etiqueta</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ea- hta- dm- enfermedad coronaria- somnolencia...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>seguimiento postquirurgico, drenaje coleccion ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>antecedente de trauma craneal e inestabilidad ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>posible sindrome de demencial. prominencia de ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>asimetria facial y craneana.sinofris. surcos y...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>654</th>\n",
              "      <td>cefalea en estudio. surcos y circunvoluciones ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>655</th>\n",
              "      <td>cefalea en estudio. surcos y circunvoluciones ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>656</th>\n",
              "      <td>paciente con hemorragia subaracnoidea, descart...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>657</th>\n",
              "      <td>nr la atenuacion del parenquima es normal para...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>658</th>\n",
              "      <td>nr cambios post craniotomia frontotemporal der...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>659 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1c93575-fffa-4f95-b3a7-b962e5cf72f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1c93575-fffa-4f95-b3a7-b962e5cf72f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1c93575-fffa-4f95-b3a7-b962e5cf72f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-284a1b0b-a31e-46eb-9e7b-08d5b9f83154\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-284a1b0b-a31e-46eb-9e7b-08d5b9f83154')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-284a1b0b-a31e-46eb-9e7b-08d5b9f83154 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e4dc08d4-ea3d-4b68-98b9-710cf82a953e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e4dc08d4-ea3d-4b68-98b9-710cf82a953e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 texto  etiqueta  label\n",
              "0    ea- hta- dm- enfermedad coronaria- somnolencia...         0      0\n",
              "1    seguimiento postquirurgico, drenaje coleccion ...         1      1\n",
              "2    antecedente de trauma craneal e inestabilidad ...         0      0\n",
              "3    posible sindrome de demencial. prominencia de ...         0      0\n",
              "4    asimetria facial y craneana.sinofris. surcos y...         0      0\n",
              "..                                                 ...       ...    ...\n",
              "654  cefalea en estudio. surcos y circunvoluciones ...         0      0\n",
              "655  cefalea en estudio. surcos y circunvoluciones ...         0      0\n",
              "656  paciente con hemorragia subaracnoidea, descart...         1      1\n",
              "657  nr la atenuacion del parenquima es normal para...         0      0\n",
              "658  nr cambios post craniotomia frontotemporal der...         0      0\n",
              "\n",
              "[659 rows x 3 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUhkOv1TZul1"
      },
      "source": [
        "## **3. Preparación del dataset para fine-tuning en formato JSONL**\n",
        "\n",
        "Se recorre el dataset de entrenamiento y para cada ejemplo se crea una estructura tipo chat con roles `\"system\"`, `\"user\"`, y `\"assistant\"`:\n",
        "\n",
        "* **system**: Se define el comportamiento esperado del modelo (ser un especialista en radiología, decidir solo con el contenido, responder solo con 1 o 0).\n",
        "* **user**: Contiene el texto real del informe radiológico.\n",
        "* **assistant**: Contiene la etiqueta real (0 o 1).\n",
        "\n",
        "Se almacena todo en formato **JSONL**, estándar para fine-tuning de modelos de lenguaje conversacional (como OpenAI GPT).\n",
        "Este formato permite que el modelo aprenda no solo la tarea, sino también el contexto conversacional y la estructura de las instrucciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y72C8-8Z0NcV"
      },
      "outputs": [],
      "source": [
        "concatenated_string_json = \"\"\n",
        "\n",
        "for index, row in df_train.iterrows():\n",
        "    # Limpia el texto\n",
        "    clean_text = str(row[\"texto\"]).replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace('\"', '\\\\\"')\n",
        "    label = str(row[\"label\"]).replace('\"', '\\\\\"')\n",
        "\n",
        "    concatenated_string_json += (\n",
        "        f'{{'\n",
        "        f'\"messages\": ['\n",
        "        f'{{ \"role\": \"system\", \"content\": \" '\n",
        "        f'Eres un especialista en radiologia, y tienes que analizar el siguiente informe radiológico escrito en español y determinar si contiene hallazgos clínicos **críticos** que requieren atención médica urgente. '\n",
        "        f'Un informe se considera crítico si describe condiciones potencialmente mortales, cambios agudos severos, o hallazgos que requieren una intervención inmediata. '\n",
        "        f'No inventes ni asumas información adicional; basa tu decisión solo en el contenido del texto. '\n",
        "        f'Responde estrictamente con un solo número: **1** si el informe es crítico, o **0** si no lo es. No añadas explicaciones ni comentarios.\" }} , '\n",
        "        f'{{ \"role\": \"user\", \"content\": \"{clean_text}\" }}, '\n",
        "        f'{{ \"role\": \"assistant\", \"content\": \"{label}\" }}'\n",
        "        f']'\n",
        "        f'}} \\n'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRwA6y1B6x9L"
      },
      "outputs": [],
      "source": [
        "with open('concatenated_string_json.jsonl', 'w') as f:\n",
        "  f.write(concatenated_string_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UynvLrDBeMo9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH52XmjnZw0k"
      },
      "source": [
        "## **4. Fine-tuning del modelo GPT con OpenAI**\n",
        "\n",
        "* **Subida del archivo**: Se sube el archivo JSONL a OpenAI usando su API, estableciendo el propósito de fine-tuning.\n",
        "* **Creación y monitoreo del trabajo de fine-tuning**: Se inicia el proceso de fine-tuning y se monitorea el progreso, mostrando eventos y el estado actual hasta que el modelo esté listo.\n",
        "* **Listar trabajos y modelos resultantes**: Se pueden listar los últimos trabajos de fine-tuning y los modelos disponibles para inferencia, incluyendo los modelos fine-tuneados específicamente para tu tarea clínica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRVK6OOCeOXK"
      },
      "source": [
        "## Finetunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oGvjVnyfxzv"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEcpeuPBfwQ6",
        "outputId": "03cd382f-44fd-4ca1-d6c9-81db4cf05732"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File uploaded: file-5fxMAEkFnxmAdCf1XcdmJ3\n"
          ]
        }
      ],
      "source": [
        "# Subir archivo jsonl for finetunning\n",
        "\n",
        "response = openai.files.create(\n",
        "    file=open(\"concatenated_string_json.jsonl\", \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "file_id = response.id\n",
        "print(\"File uploaded:\", file_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE67vKX0guNH"
      },
      "source": [
        "Iniciar el finetunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6Ad0cYveNjc",
        "outputId": "3bbcdb6a-eda3-4ab7-e653-919b3069ca7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tune job started: ftjob-JBXGZMskmrvK7dvrnPkRzPYr\n"
          ]
        }
      ],
      "source": [
        "fine_tune_response = openai.fine_tuning.jobs.create(\n",
        "    training_file=file_id,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")\n",
        "print(\"Fine-tune job started:\", fine_tune_response.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YRvJSNMgz8C",
        "outputId": "97b06ef3-c14a-4b2f-cd82-062a24e4403d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Status: validating_files\n",
            "Validating training file: file-5fxMAEkFnxmAdCf1XcdmJ3\n",
            "Created fine-tuning job: ftjob-JBXGZMskmrvK7dvrnPkRzPYr\n"
          ]
        }
      ],
      "source": [
        "# Ver el estado del trabajo\n",
        "status = openai.fine_tuning.jobs.retrieve(fine_tune_response.id)\n",
        "print(\"Status:\", status.status)\n",
        "\n",
        "events = openai.fine_tuning.jobs.list_events(fine_tuning_job_id=fine_tune_response.id)\n",
        "for event in events.data:\n",
        "    print(event.message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zl08kHvZ14v"
      },
      "source": [
        "## **5. Inferencia con el modelo fine-tuneado**\n",
        "\n",
        "* Se define una función para consultar el modelo fine-tuneado dado un texto de informe. La función:\n",
        "\n",
        "  * Usa las mismas instrucciones de contexto.\n",
        "  * Envía el texto al modelo vía API.\n",
        "  * Recupera la predicción (0 o 1) como respuesta determinista.\n",
        "* Se aplica esta función a todo el conjunto de validación/test, generando las predicciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LekfWqkehrLx",
        "outputId": "0df7394a-8d6e-4127-cbcc-588762abb2e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⏳ Monitoreando el fine-tuning con ID: ftjob-JBXGZMskmrvK7dvrnPkRzPYr\n",
            "\n",
            "📌 Estado actual: running\n",
            "[1747406483] Step 158/1692: training loss=0.00\n",
            "[1747406486] Step 159/1692: training loss=0.12\n",
            "[1747406486] Step 160/1692: training loss=0.44\n",
            "[1747406488] Step 161/1692: training loss=0.01\n",
            "[1747406489] Step 162/1692: training loss=0.00\n",
            "[1747406489] Step 163/1692: training loss=0.00\n",
            "[1747406491] Step 164/1692: training loss=0.00\n",
            "[1747406494] Step 165/1692: training loss=0.00\n",
            "[1747406494] Step 166/1692: training loss=0.00\n",
            "[1747406494] Step 167/1692: training loss=0.00\n",
            "[1747406497] Step 168/1692: training loss=0.00\n",
            "[1747406499] Step 169/1692: training loss=0.01\n",
            "[1747406524] Step 170/1692: training loss=0.72\n",
            "[1747406527] Step 171/1692: training loss=0.20\n",
            "[1747406527] Step 172/1692: training loss=0.41\n",
            "[1747406529] Step 173/1692: training loss=0.00\n",
            "[1747406530] Step 174/1692: training loss=1.43\n",
            "[1747406532] Step 175/1692: training loss=1.76\n",
            "[1747406532] Step 176/1692: training loss=0.90\n",
            "[1747406535] Step 177/1692: training loss=0.08\n",
            "📌 Estado actual: running\n",
            "[1747406535] Step 178/1692: training loss=0.03\n",
            "[1747406538] Step 179/1692: training loss=0.84\n",
            "[1747406538] Step 180/1692: training loss=0.82\n",
            "[1747406541] Step 181/1692: training loss=0.65\n",
            "[1747406541] Step 182/1692: training loss=0.00\n",
            "[1747406544] Step 183/1692: training loss=0.00\n",
            "[1747406544] Step 184/1692: training loss=0.00\n",
            "[1747406546] Step 185/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406547] Step 186/1692: training loss=0.00\n",
            "[1747406549] Step 187/1692: training loss=0.00\n",
            "[1747406549] Step 188/1692: training loss=0.00\n",
            "[1747406552] Step 189/1692: training loss=0.00\n",
            "[1747406552] Step 190/1692: training loss=0.57\n",
            "[1747406555] Step 191/1692: training loss=0.00\n",
            "[1747406555] Step 192/1692: training loss=0.00\n",
            "[1747406558] Step 193/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406558] Step 194/1692: training loss=0.90\n",
            "[1747406560] Step 195/1692: training loss=0.00\n",
            "[1747406560] Step 196/1692: training loss=0.01\n",
            "[1747406563] Step 197/1692: training loss=1.20\n",
            "📌 Estado actual: running\n",
            "[1747406572] Step 198/1692: training loss=0.17\n",
            "[1747406574] Step 199/1692: training loss=0.00\n",
            "[1747406574] Step 200/1692: training loss=0.77\n",
            "[1747406577] Step 201/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406577] Step 202/1692: training loss=0.00\n",
            "[1747406580] Step 203/1692: training loss=0.00\n",
            "[1747406580] Step 204/1692: training loss=0.00\n",
            "[1747406583] Step 205/1692: training loss=0.00\n",
            "[1747406583] Step 206/1692: training loss=1.31\n",
            "[1747406586] Step 207/1692: training loss=0.00\n",
            "[1747406586] Step 208/1692: training loss=0.00\n",
            "[1747406588] Step 209/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406588] Step 210/1692: training loss=0.00\n",
            "[1747406591] Step 211/1692: training loss=0.00\n",
            "[1747406591] Step 212/1692: training loss=0.00\n",
            "[1747406594] Step 213/1692: training loss=0.00\n",
            "[1747406594] Step 214/1692: training loss=0.00\n",
            "[1747406597] Step 215/1692: training loss=1.20\n",
            "[1747406597] Step 216/1692: training loss=0.00\n",
            "[1747406599] Step 217/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406602] Step 218/1692: training loss=0.99\n",
            "[1747406602] Step 219/1692: training loss=0.00\n",
            "[1747406602] Step 220/1692: training loss=0.00\n",
            "[1747406605] Step 221/1692: training loss=1.04\n",
            "[1747406605] Step 222/1692: training loss=0.00\n",
            "[1747406608] Step 223/1692: training loss=0.83\n",
            "[1747406608] Step 224/1692: training loss=0.00\n",
            "[1747406611] Step 225/1692: training loss=0.81\n",
            "📌 Estado actual: running\n",
            "[1747406611] Step 226/1692: training loss=0.00\n",
            "[1747406614] Step 227/1692: training loss=0.00\n",
            "[1747406619] Step 228/1692: training loss=0.79\n",
            "📌 Estado actual: running\n",
            "[1747406619] Step 229/1692: training loss=0.00\n",
            "[1747406622] Step 230/1692: training loss=0.00\n",
            "[1747406622] Step 231/1692: training loss=0.79\n",
            "[1747406625] Step 232/1692: training loss=0.72\n",
            "[1747406625] Step 233/1692: training loss=0.00\n",
            "[1747406627] Step 234/1692: training loss=0.01\n",
            "[1747406627] Step 235/1692: training loss=0.00\n",
            "[1747406630] Step 236/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "📌 Estado actual: running\n",
            "📌 Estado actual: running\n",
            "[1747406630] Step 237/1692: training loss=0.70\n",
            "[1747406660] Step 238/1692: training loss=0.06\n",
            "📌 Estado actual: running\n",
            "[1747406660] Step 239/1692: training loss=0.00\n",
            "[1747406663] Step 240/1692: training loss=0.00\n",
            "[1747406663] Step 241/1692: training loss=0.00\n",
            "[1747406666] Step 242/1692: training loss=0.61\n",
            "[1747406666] Step 243/1692: training loss=0.93\n",
            "[1747406669] Step 244/1692: training loss=0.00\n",
            "[1747406669] Step 245/1692: training loss=0.00\n",
            "[1747406671] Step 246/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406672] Step 247/1692: training loss=0.00\n",
            "[1747406674] Step 248/1692: training loss=0.79\n",
            "[1747406674] Step 249/1692: training loss=0.71\n",
            "[1747406677] Step 250/1692: training loss=0.36\n",
            "[1747406680] Step 251/1692: training loss=0.00\n",
            "[1747406680] Step 252/1692: training loss=0.71\n",
            "[1747406680] Step 253/1692: training loss=0.00\n",
            "[1747406683] Step 254/1692: training loss=0.73\n",
            "📌 Estado actual: running\n",
            "[1747406683] Step 255/1692: training loss=0.00\n",
            "[1747406685] Step 256/1692: training loss=0.23\n",
            "[1747406688] Step 257/1692: training loss=0.55\n",
            "[1747406688] Step 258/1692: training loss=0.00\n",
            "[1747406691] Step 259/1692: training loss=0.00\n",
            "[1747406691] Step 260/1692: training loss=0.00\n",
            "[1747406694] Step 261/1692: training loss=0.22\n",
            "📌 Estado actual: running\n",
            "[1747406694] Step 262/1692: training loss=0.00\n",
            "[1747406697] Step 263/1692: training loss=0.00\n",
            "[1747406697] Step 264/1692: training loss=0.00\n",
            "[1747406697] Step 265/1692: training loss=0.00\n",
            "[1747406699] Step 266/1692: training loss=0.00\n",
            "[1747406700] Step 267/1692: training loss=0.67\n",
            "[1747406702] Step 268/1692: training loss=0.00\n",
            "[1747406702] Step 269/1692: training loss=0.00\n",
            "[1747406705] Step 270/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406708] Step 271/1692: training loss=0.00\n",
            "[1747406708] Step 272/1692: training loss=0.00\n",
            "[1747406708] Step 273/1692: training loss=0.00\n",
            "[1747406711] Step 274/1692: training loss=0.00\n",
            "[1747406711] Step 275/1692: training loss=0.80\n",
            "[1747406713] Step 276/1692: training loss=0.60\n",
            "[1747406716] Step 277/1692: training loss=0.54\n",
            "📌 Estado actual: running\n",
            "[1747406716] Step 278/1692: training loss=0.88\n",
            "[1747406719] Step 279/1692: training loss=0.00\n",
            "[1747406719] Step 280/1692: training loss=0.75\n",
            "[1747406722] Step 281/1692: training loss=0.98\n",
            "📌 Estado actual: running\n",
            "[1747406722] Step 282/1692: training loss=0.60\n",
            "[1747406725] Step 283/1692: training loss=1.61\n",
            "[1747406725] Step 284/1692: training loss=0.00\n",
            "[1747406728] Step 285/1692: training loss=0.00\n",
            "[1747406728] Step 286/1692: training loss=2.01\n",
            "[1747406730] Step 287/1692: training loss=0.50\n",
            "[1747406730] Step 288/1692: training loss=0.00\n",
            "[1747406730] Step 289/1692: training loss=0.00\n",
            "[1747406733] Step 290/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406736] Step 291/1692: training loss=0.00\n",
            "[1747406736] Step 292/1692: training loss=0.00\n",
            "[1747406739] Step 293/1692: training loss=0.00\n",
            "[1747406739] Step 294/1692: training loss=0.00\n",
            "[1747406742] Step 295/1692: training loss=0.00\n",
            "[1747406742] Step 296/1692: training loss=0.00\n",
            "[1747406744] Step 297/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406744] Step 298/1692: training loss=0.00\n",
            "[1747406747] Step 299/1692: training loss=0.00\n",
            "[1747406747] Step 300/1692: training loss=0.80\n",
            "[1747406750] Step 301/1692: training loss=0.06\n",
            "[1747406750] Step 302/1692: training loss=0.96\n",
            "[1747406753] Step 303/1692: training loss=1.17\n",
            "[1747406753] Step 304/1692: training loss=0.79\n",
            "[1747406755] Step 305/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406756] Step 306/1692: training loss=0.00\n",
            "[1747406758] Step 307/1692: training loss=0.00\n",
            "[1747406758] Step 308/1692: training loss=0.00\n",
            "[1747406761] Step 309/1692: training loss=0.00\n",
            "[1747406761] Step 310/1692: training loss=0.30\n",
            "[1747406764] Step 311/1692: training loss=0.00\n",
            "[1747406764] Step 312/1692: training loss=0.00\n",
            "[1747406768] Step 313/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406768] Step 314/1692: training loss=0.00\n",
            "[1747406768] Step 315/1692: training loss=0.00\n",
            "[1747406771] Step 316/1692: training loss=0.00\n",
            "[1747406771] Step 317/1692: training loss=0.60\n",
            "[1747406773] Step 318/1692: training loss=0.00\n",
            "[1747406773] Step 319/1692: training loss=0.00\n",
            "[1747406776] Step 320/1692: training loss=0.00\n",
            "[1747406779] Step 321/1692: training loss=0.64\n",
            "📌 Estado actual: running\n",
            "[1747406779] Step 322/1692: training loss=0.00\n",
            "[1747406782] Step 323/1692: training loss=0.56\n",
            "[1747406782] Step 324/1692: training loss=0.00\n",
            "[1747406782] Step 325/1692: training loss=0.00\n",
            "[1747406784] Step 326/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406787] Step 327/1692: training loss=0.00\n",
            "[1747406787] Step 328/1692: training loss=0.00\n",
            "[1747406790] Step 329/1692: training loss=0.00\n",
            "[1747406790] Step 330/1692: training loss=0.00\n",
            "[1747406793] Step 331/1692: training loss=0.79\n",
            "[1747406793] Step 332/1692: training loss=0.67\n",
            "[1747406793] Step 333/1692: training loss=0.00\n",
            "[1747406796] Step 334/1692: training loss=0.67\n",
            "📌 Estado actual: running\n",
            "[1747406799] Step 335/1692: training loss=0.00\n",
            "[1747406799] Step 336/1692: training loss=0.00\n",
            "[1747406801] Step 337/1692: training loss=0.00\n",
            "[1747406801] Step 338/1692: training loss=0.60\n",
            "[1747406804] Step 339/1692: training loss=0.00\n",
            "[1747406804] Step 340/1692: training loss=0.00\n",
            "[1747406807] Step 341/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406807] Step 342/1692: training loss=0.00\n",
            "[1747406810] Step 343/1692: training loss=0.67\n",
            "[1747406810] Step 344/1692: training loss=0.00\n",
            "[1747406813] Step 345/1692: training loss=0.00\n",
            "[1747406813] Step 346/1692: training loss=0.00\n",
            "[1747406815] Step 347/1692: training loss=0.73\n",
            "[1747406815] Step 348/1692: training loss=0.70\n",
            "[1747406818] Step 349/1692: training loss=1.00\n",
            "📌 Estado actual: running\n",
            "[1747406818] Step 350/1692: training loss=0.08\n",
            "[1747406821] Step 351/1692: training loss=0.00\n",
            "[1747406821] Step 352/1692: training loss=0.52\n",
            "[1747406824] Step 353/1692: training loss=0.00\n",
            "[1747406824] Step 354/1692: training loss=0.00\n",
            "[1747406827] Step 355/1692: training loss=1.09\n",
            "[1747406827] Step 356/1692: training loss=1.03\n",
            "[1747406827] Step 357/1692: training loss=0.04\n",
            "[1747406830] Step 358/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406833] Step 359/1692: training loss=1.25\n",
            "[1747406833] Step 360/1692: training loss=0.62\n",
            "[1747406835] Step 361/1692: training loss=0.55\n",
            "[1747406836] Step 362/1692: training loss=0.52\n",
            "[1747406838] Step 363/1692: training loss=0.32\n",
            "[1747406838] Step 364/1692: training loss=0.44\n",
            "[1747406841] Step 365/1692: training loss=0.61\n",
            "📌 Estado actual: running\n",
            "[1747406841] Step 366/1692: training loss=0.00\n",
            "[1747406844] Step 367/1692: training loss=0.33\n",
            "[1747406844] Step 368/1692: training loss=0.00\n",
            "[1747406846] Step 369/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406847] Step 370/1692: training loss=0.00\n",
            "[1747406849] Step 371/1692: training loss=0.00\n",
            "[1747406849] Step 372/1692: training loss=0.24\n",
            "[1747406852] Step 373/1692: training loss=0.68\n",
            "[1747406853] Step 374/1692: training loss=0.01\n",
            "[1747406855] Step 375/1692: training loss=0.70\n",
            "[1747406855] Step 376/1692: training loss=0.44\n",
            "[1747406858] Step 377/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406858] Step 378/1692: training loss=0.02\n",
            "[1747406861] Step 379/1692: training loss=0.05\n",
            "[1747406861] Step 380/1692: training loss=0.00\n",
            "[1747406864] Step 381/1692: training loss=0.00\n",
            "[1747406864] Step 382/1692: training loss=0.00\n",
            "[1747406866] Step 383/1692: training loss=0.00\n",
            "[1747406866] Step 384/1692: training loss=0.00\n",
            "[1747406869] Step 385/1692: training loss=0.02\n",
            "📌 Estado actual: running\n",
            "[1747406869] Step 386/1692: training loss=0.00\n",
            "[1747406872] Step 387/1692: training loss=0.00\n",
            "[1747406872] Step 388/1692: training loss=0.00\n",
            "[1747406875] Step 389/1692: training loss=0.00\n",
            "[1747406875] Step 390/1692: training loss=0.00\n",
            "[1747406878] Step 391/1692: training loss=0.00\n",
            "[1747406878] Step 392/1692: training loss=0.62\n",
            "[1747406880] Step 393/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406880] Step 394/1692: training loss=0.00\n",
            "[1747406883] Step 395/1692: training loss=0.00\n",
            "[1747406883] Step 396/1692: training loss=0.00\n",
            "[1747406886] Step 397/1692: training loss=0.00\n",
            "[1747406886] Step 398/1692: training loss=0.00\n",
            "[1747406889] Step 399/1692: training loss=0.00\n",
            "[1747406889] Step 400/1692: training loss=2.40\n",
            "[1747406892] Step 401/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406892] Step 402/1692: training loss=0.00\n",
            "[1747406895] Step 403/1692: training loss=0.00\n",
            "[1747406895] Step 404/1692: training loss=0.00\n",
            "[1747406897] Step 405/1692: training loss=0.00\n",
            "[1747406897] Step 406/1692: training loss=0.00\n",
            "[1747406900] Step 407/1692: training loss=0.00\n",
            "[1747406900] Step 408/1692: training loss=1.04\n",
            "[1747406903] Step 409/1692: training loss=1.00\n",
            "📌 Estado actual: running\n",
            "[1747406903] Step 410/1692: training loss=0.00\n",
            "[1747406906] Step 411/1692: training loss=0.00\n",
            "[1747406906] Step 412/1692: training loss=0.00\n",
            "[1747406908] Step 413/1692: training loss=0.00\n",
            "[1747406909] Step 414/1692: training loss=0.00\n",
            "[1747406911] Step 415/1692: training loss=0.76\n",
            "[1747406911] Step 416/1692: training loss=0.00\n",
            "[1747406914] Step 417/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406914] Step 418/1692: training loss=1.44\n",
            "[1747406917] Step 419/1692: training loss=0.00\n",
            "[1747406917] Step 420/1692: training loss=0.80\n",
            "[1747406920] Step 421/1692: training loss=0.00\n",
            "[1747406920] Step 422/1692: training loss=0.00\n",
            "[1747406923] Step 423/1692: training loss=0.00\n",
            "[1747406923] Step 424/1692: training loss=0.00\n",
            "[1747406925] Step 425/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406926] Step 426/1692: training loss=0.00\n",
            "[1747406928] Step 427/1692: training loss=0.28\n",
            "[1747406928] Step 428/1692: training loss=0.00\n",
            "[1747406931] Step 429/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406934] Step 430/1692: training loss=0.40\n",
            "[1747406934] Step 431/1692: training loss=0.00\n",
            "[1747406937] Step 432/1692: training loss=0.00\n",
            "[1747406937] Step 433/1692: training loss=0.00\n",
            "[1747406937] Step 434/1692: training loss=0.00\n",
            "[1747406939] Step 435/1692: training loss=0.00\n",
            "[1747406942] Step 436/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406942] Step 437/1692: training loss=0.00\n",
            "[1747406945] Step 438/1692: training loss=0.00\n",
            "[1747406945] Step 439/1692: training loss=0.00\n",
            "[1747406948] Step 440/1692: training loss=0.00\n",
            "[1747406948] Step 441/1692: training loss=0.00\n",
            "[1747406951] Step 442/1692: training loss=0.81\n",
            "[1747406951] Step 443/1692: training loss=0.86\n",
            "[1747406951] Step 444/1692: training loss=0.00\n",
            "[1747406953] Step 445/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406956] Step 446/1692: training loss=0.00\n",
            "[1747406956] Step 447/1692: training loss=0.70\n",
            "[1747406959] Step 448/1692: training loss=0.00\n",
            "[1747406959] Step 449/1692: training loss=0.00\n",
            "[1747406962] Step 450/1692: training loss=0.30\n",
            "[1747406962] Step 451/1692: training loss=0.00\n",
            "[1747406965] Step 452/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406965] Step 453/1692: training loss=0.76\n",
            "[1747406968] Step 454/1692: training loss=0.00\n",
            "[1747406968] Step 455/1692: training loss=0.00\n",
            "[1747406970] Step 456/1692: training loss=0.00\n",
            "[1747406970] Step 457/1692: training loss=0.43\n",
            "[1747406973] Step 458/1692: training loss=0.00\n",
            "[1747406973] Step 459/1692: training loss=0.67\n",
            "[1747406976] Step 460/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406976] Step 461/1692: training loss=0.00\n",
            "[1747406979] Step 462/1692: training loss=0.00\n",
            "[1747406979] Step 463/1692: training loss=0.00\n",
            "[1747406982] Step 464/1692: training loss=0.00\n",
            "[1747406982] Step 465/1692: training loss=0.00\n",
            "[1747406984] Step 466/1692: training loss=0.00\n",
            "[1747406984] Step 467/1692: training loss=0.00\n",
            "[1747406987] Step 468/1692: training loss=1.45\n",
            "📌 Estado actual: running\n",
            "[1747406987] Step 469/1692: training loss=0.00\n",
            "[1747406990] Step 470/1692: training loss=0.00\n",
            "[1747406990] Step 471/1692: training loss=0.00\n",
            "[1747406993] Step 472/1692: training loss=0.00\n",
            "[1747406993] Step 473/1692: training loss=0.69\n",
            "[1747406996] Step 474/1692: training loss=0.00\n",
            "[1747406996] Step 475/1692: training loss=0.00\n",
            "[1747406998] Step 476/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747406998] Step 477/1692: training loss=0.00\n",
            "[1747407001] Step 478/1692: training loss=0.00\n",
            "[1747407001] Step 479/1692: training loss=0.00\n",
            "[1747407004] Step 480/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407004] Step 481/1692: training loss=0.04\n",
            "[1747407007] Step 482/1692: training loss=0.00\n",
            "[1747407007] Step 483/1692: training loss=0.00\n",
            "[1747407010] Step 484/1692: training loss=0.00\n",
            "[1747407010] Step 485/1692: training loss=0.00\n",
            "[1747407013] Step 486/1692: training loss=0.76\n",
            "[1747407013] Step 487/1692: training loss=0.00\n",
            "[1747407015] Step 488/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407015] Step 489/1692: training loss=1.24\n",
            "[1747407018] Step 490/1692: training loss=0.00\n",
            "[1747407021] Step 491/1692: training loss=0.00\n",
            "[1747407021] Step 492/1692: training loss=0.00\n",
            "[1747407024] Step 493/1692: training loss=0.00\n",
            "[1747407024] Step 494/1692: training loss=0.00\n",
            "[1747407024] Step 495/1692: training loss=0.00\n",
            "[1747407026] Step 496/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407029] Step 497/1692: training loss=0.00\n",
            "[1747407029] Step 498/1692: training loss=0.67\n",
            "[1747407032] Step 499/1692: training loss=0.00\n",
            "[1747407032] Step 500/1692: training loss=0.00\n",
            "[1747407035] Step 501/1692: training loss=0.00\n",
            "[1747407035] Step 502/1692: training loss=0.00\n",
            "[1747407038] Step 503/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407038] Step 504/1692: training loss=0.00\n",
            "[1747407041] Step 505/1692: training loss=0.00\n",
            "[1747407041] Step 506/1692: training loss=0.00\n",
            "[1747407043] Step 507/1692: training loss=0.73\n",
            "[1747407044] Step 508/1692: training loss=0.00\n",
            "[1747407046] Step 509/1692: training loss=0.00\n",
            "[1747407046] Step 510/1692: training loss=0.00\n",
            "[1747407049] Step 511/1692: training loss=0.78\n",
            "📌 Estado actual: running\n",
            "[1747407049] Step 512/1692: training loss=0.06\n",
            "[1747407052] Step 513/1692: training loss=0.00\n",
            "[1747407052] Step 514/1692: training loss=0.00\n",
            "[1747407055] Step 515/1692: training loss=0.84\n",
            "[1747407055] Step 516/1692: training loss=0.00\n",
            "[1747407057] Step 517/1692: training loss=0.60\n",
            "[1747407057] Step 518/1692: training loss=0.00\n",
            "[1747407060] Step 519/1692: training loss=0.95\n",
            "📌 Estado actual: running\n",
            "[1747407060] Step 520/1692: training loss=0.00\n",
            "[1747407063] Step 521/1692: training loss=0.00\n",
            "[1747407063] Step 522/1692: training loss=0.00\n",
            "[1747407066] Step 523/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407066] Step 524/1692: training loss=0.00\n",
            "[1747407069] Step 525/1692: training loss=0.00\n",
            "[1747407069] Step 526/1692: training loss=0.00\n",
            "[1747407072] Step 527/1692: training loss=0.00\n",
            "[1747407072] Step 528/1692: training loss=0.61\n",
            "[1747407074] Step 529/1692: training loss=0.00\n",
            "[1747407074] Step 530/1692: training loss=0.00\n",
            "[1747407077] Step 531/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407077] Step 532/1692: training loss=0.00\n",
            "[1747407080] Step 533/1692: training loss=0.79\n",
            "[1747407080] Step 534/1692: training loss=0.00\n",
            "[1747407083] Step 535/1692: training loss=0.00\n",
            "[1747407083] Step 536/1692: training loss=0.00\n",
            "[1747407086] Step 537/1692: training loss=0.00\n",
            "[1747407086] Step 538/1692: training loss=1.54\n",
            "[1747407088] Step 539/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407088] Step 540/1692: training loss=0.00\n",
            "[1747407091] Step 541/1692: training loss=0.00\n",
            "[1747407091] Step 542/1692: training loss=0.85\n",
            "[1747407094] Step 543/1692: training loss=0.00\n",
            "[1747407094] Step 544/1692: training loss=0.87\n",
            "[1747407097] Step 545/1692: training loss=0.00\n",
            "[1747407097] Step 546/1692: training loss=0.75\n",
            "[1747407100] Step 547/1692: training loss=2.06\n",
            "📌 Estado actual: running\n",
            "[1747407100] Step 548/1692: training loss=0.73\n",
            "[1747407103] Step 549/1692: training loss=0.00\n",
            "[1747407103] Step 550/1692: training loss=0.00\n",
            "[1747407105] Step 551/1692: training loss=0.00\n",
            "[1747407106] Step 552/1692: training loss=0.00\n",
            "[1747407108] Step 553/1692: training loss=0.00\n",
            "[1747407108] Step 554/1692: training loss=0.00\n",
            "[1747407111] Step 555/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407111] Step 556/1692: training loss=0.81\n",
            "[1747407114] Step 557/1692: training loss=0.00\n",
            "[1747407114] Step 558/1692: training loss=0.55\n",
            "[1747407116] Step 559/1692: training loss=0.89\n",
            "[1747407117] Step 560/1692: training loss=0.00\n",
            "[1747407119] Step 561/1692: training loss=0.00\n",
            "[1747407119] Step 562/1692: training loss=0.74\n",
            "[1747407122] Step 563/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407122] Step 564/1692: training loss=0.00\n",
            "[1747407128] Step 565/1692: training loss=0.00\n",
            "[1747407128] Step 566/1692: training loss=0.00\n",
            "[1747407128] Step 567/1692: training loss=0.00\n",
            "[1747407131] Step 568/1692: training loss=0.00\n",
            "[1747407131] Step 569/1692: training loss=0.00\n",
            "[1747407134] Step 570/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407137] Step 571/1692: training loss=0.00\n",
            "[1747407137] Step 572/1692: training loss=0.00\n",
            "[1747407137] Step 573/1692: training loss=0.00\n",
            "[1747407139] Step 574/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "📌 Estado actual: running\n",
            "[1747407140] Step 575/1692: training loss=0.00\n",
            "[1747407142] Step 576/1692: training loss=0.88\n",
            "[1747407142] Step 577/1692: training loss=0.00\n",
            "[1747407161] Step 578/1692: training loss=0.83\n",
            "📌 Estado actual: running\n",
            "[1747407161] Step 579/1692: training loss=0.00\n",
            "[1747407164] Step 580/1692: training loss=0.00\n",
            "[1747407164] Step 581/1692: training loss=0.00\n",
            "[1747407167] Step 582/1692: training loss=0.00\n",
            "[1747407167] Step 583/1692: training loss=0.00\n",
            "[1747407170] Step 584/1692: training loss=0.00\n",
            "[1747407170] Step 585/1692: training loss=0.00\n",
            "[1747407170] Step 586/1692: training loss=0.89\n",
            "[1747407172] Step 587/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407175] Step 588/1692: training loss=0.00\n",
            "[1747407175] Step 589/1692: training loss=0.00\n",
            "[1747407178] Step 590/1692: training loss=0.00\n",
            "[1747407178] Step 591/1692: training loss=0.59\n",
            "[1747407181] Step 592/1692: training loss=0.00\n",
            "[1747407181] Step 593/1692: training loss=0.81\n",
            "[1747407184] Step 594/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407184] Step 595/1692: training loss=0.00\n",
            "[1747407186] Step 596/1692: training loss=0.00\n",
            "[1747407186] Step 597/1692: training loss=0.00\n",
            "[1747407189] Step 598/1692: training loss=0.79\n",
            "[1747407189] Step 599/1692: training loss=0.00\n",
            "[1747407192] Step 600/1692: training loss=0.00\n",
            "[1747407192] Step 601/1692: training loss=0.00\n",
            "[1747407195] Step 602/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407195] Step 603/1692: training loss=0.04\n",
            "[1747407198] Step 604/1692: training loss=0.93\n",
            "[1747407198] Step 605/1692: training loss=0.88\n",
            "[1747407201] Step 606/1692: training loss=0.00\n",
            "[1747407201] Step 607/1692: training loss=0.00\n",
            "[1747407203] Step 608/1692: training loss=0.00\n",
            "[1747407203] Step 609/1692: training loss=0.74\n",
            "[1747407206] Step 610/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407206] Step 611/1692: training loss=0.00\n",
            "[1747407209] Step 612/1692: training loss=0.00\n",
            "[1747407209] Step 613/1692: training loss=0.00\n",
            "[1747407212] Step 614/1692: training loss=0.72\n",
            "[1747407212] Step 615/1692: training loss=1.44\n",
            "[1747407215] Step 616/1692: training loss=0.76\n",
            "[1747407215] Step 617/1692: training loss=0.00\n",
            "[1747407217] Step 618/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407217] Step 619/1692: training loss=0.00\n",
            "[1747407220] Step 620/1692: training loss=0.00\n",
            "[1747407220] Step 621/1692: training loss=0.00\n",
            "[1747407223] Step 622/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407223] Step 623/1692: training loss=0.00\n",
            "[1747407226] Step 624/1692: training loss=0.00\n",
            "[1747407226] Step 625/1692: training loss=0.00\n",
            "[1747407229] Step 626/1692: training loss=0.00\n",
            "[1747407232] Step 627/1692: training loss=0.00\n",
            "[1747407232] Step 628/1692: training loss=0.44\n",
            "[1747407232] Step 629/1692: training loss=0.00\n",
            "[1747407234] Step 630/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407237] Step 631/1692: training loss=0.00\n",
            "[1747407237] Step 632/1692: training loss=0.00\n",
            "[1747407237] Step 633/1692: training loss=0.00\n",
            "[1747407240] Step 634/1692: training loss=0.00\n",
            "[1747407243] Step 635/1692: training loss=0.00\n",
            "[1747407243] Step 636/1692: training loss=0.00\n",
            "[1747407245] Step 637/1692: training loss=0.77\n",
            "📌 Estado actual: running\n",
            "[1747407246] Step 638/1692: training loss=0.00\n",
            "[1747407248] Step 639/1692: training loss=0.00\n",
            "[1747407248] Step 640/1692: training loss=0.00\n",
            "[1747407251] Step 641/1692: training loss=0.00\n",
            "[1747407251] Step 642/1692: training loss=1.01\n",
            "[1747407254] Step 643/1692: training loss=0.00\n",
            "[1747407254] Step 644/1692: training loss=0.98\n",
            "[1747407257] Step 645/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407257] Step 646/1692: training loss=0.00\n",
            "[1747407260] Step 647/1692: training loss=0.00\n",
            "[1747407260] Step 648/1692: training loss=0.81\n",
            "[1747407262] Step 649/1692: training loss=0.00\n",
            "[1747407262] Step 650/1692: training loss=0.00\n",
            "[1747407265] Step 651/1692: training loss=0.00\n",
            "[1747407265] Step 652/1692: training loss=0.00\n",
            "[1747407268] Step 653/1692: training loss=0.78\n",
            "📌 Estado actual: running\n",
            "[1747407268] Step 654/1692: training loss=0.00\n",
            "[1747407271] Step 655/1692: training loss=0.00\n",
            "[1747407271] Step 656/1692: training loss=0.00\n",
            "[1747407273] Step 657/1692: training loss=0.00\n",
            "[1747407274] Step 658/1692: training loss=0.71\n",
            "[1747407276] Step 659/1692: training loss=0.52\n",
            "[1747407276] Step 660/1692: training loss=0.00\n",
            "[1747407279] Step 661/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407279] Step 662/1692: training loss=0.00\n",
            "[1747407282] Step 663/1692: training loss=0.00\n",
            "[1747407282] Step 664/1692: training loss=0.00\n",
            "[1747407285] Step 665/1692: training loss=0.00\n",
            "[1747407285] Step 666/1692: training loss=0.72\n",
            "[1747407288] Step 667/1692: training loss=0.66\n",
            "[1747407288] Step 668/1692: training loss=0.67\n",
            "[1747407290] Step 669/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407291] Step 670/1692: training loss=0.00\n",
            "[1747407293] Step 671/1692: training loss=0.00\n",
            "[1747407293] Step 672/1692: training loss=0.00\n",
            "[1747407296] Step 673/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407296] Step 674/1692: training loss=0.00\n",
            "[1747407299] Step 675/1692: training loss=0.00\n",
            "[1747407299] Step 676/1692: training loss=0.47\n",
            "[1747407302] Step 677/1692: training loss=0.00\n",
            "[1747407302] Step 678/1692: training loss=0.00\n",
            "[1747407305] Step 679/1692: training loss=0.00\n",
            "[1747407305] Step 680/1692: training loss=0.00\n",
            "[1747407307] Step 681/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407308] Step 682/1692: training loss=0.89\n",
            "[1747407310] Step 683/1692: training loss=0.00\n",
            "[1747407310] Step 684/1692: training loss=0.00\n",
            "[1747407313] Step 685/1692: training loss=0.85\n",
            "[1747407313] Step 686/1692: training loss=0.00\n",
            "[1747407316] Step 687/1692: training loss=0.74\n",
            "[1747407316] Step 688/1692: training loss=0.00\n",
            "[1747407319] Step 689/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407319] Step 690/1692: training loss=0.00\n",
            "[1747407322] Step 691/1692: training loss=0.00\n",
            "[1747407322] Step 692/1692: training loss=0.50\n",
            "[1747407324] Step 693/1692: training loss=0.00\n",
            "[1747407324] Step 694/1692: training loss=0.67\n",
            "[1747407327] Step 695/1692: training loss=0.49\n",
            "[1747407327] Step 696/1692: training loss=0.00\n",
            "[1747407330] Step 697/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407330] Step 698/1692: training loss=0.00\n",
            "[1747407333] Step 699/1692: training loss=0.00\n",
            "[1747407333] Step 700/1692: training loss=0.00\n",
            "[1747407335] Step 701/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407338] Step 702/1692: training loss=0.00\n",
            "[1747407338] Step 703/1692: training loss=0.82\n",
            "[1747407349] Step 704/1692: training loss=0.98\n",
            "[1747407352] Step 705/1692: training loss=0.00\n",
            "[1747407355] Step 706/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407355] Step 707/1692: training loss=0.00\n",
            "[1747407358] Step 708/1692: training loss=0.00\n",
            "[1747407358] Step 709/1692: training loss=0.00\n",
            "[1747407360] Step 710/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407361] Step 711/1692: training loss=0.00\n",
            "[1747407363] Step 712/1692: training loss=0.00\n",
            "[1747407363] Step 713/1692: training loss=0.00\n",
            "[1747407366] Step 714/1692: training loss=0.00\n",
            "[1747407366] Step 715/1692: training loss=0.61\n",
            "[1747407369] Step 716/1692: training loss=0.00\n",
            "[1747407369] Step 717/1692: training loss=0.00\n",
            "[1747407371] Step 718/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407372] Step 719/1692: training loss=0.00\n",
            "[1747407374] Step 720/1692: training loss=0.84\n",
            "[1747407374] Step 721/1692: training loss=0.00\n",
            "[1747407377] Step 722/1692: training loss=0.00\n",
            "[1747407378] Step 723/1692: training loss=0.00\n",
            "[1747407380] Step 724/1692: training loss=0.00\n",
            "[1747407380] Step 725/1692: training loss=0.00\n",
            "[1747407383] Step 726/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407383] Step 727/1692: training loss=0.00\n",
            "[1747407386] Step 728/1692: training loss=0.00\n",
            "[1747407386] Step 729/1692: training loss=0.00\n",
            "[1747407388] Step 730/1692: training loss=0.00\n",
            "[1747407389] Step 731/1692: training loss=0.00\n",
            "[1747407391] Step 732/1692: training loss=0.74\n",
            "[1747407391] Step 733/1692: training loss=0.32\n",
            "[1747407394] Step 734/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407394] Step 735/1692: training loss=0.00\n",
            "[1747407397] Step 736/1692: training loss=0.00\n",
            "[1747407397] Step 737/1692: training loss=0.00\n",
            "[1747407400] Step 738/1692: training loss=0.00\n",
            "[1747407400] Step 739/1692: training loss=0.00\n",
            "[1747407402] Step 740/1692: training loss=0.00\n",
            "[1747407403] Step 741/1692: training loss=0.00\n",
            "[1747407405] Step 742/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407406] Step 743/1692: training loss=0.00\n",
            "[1747407409] Step 744/1692: training loss=1.59\n",
            "[1747407409] Step 745/1692: training loss=0.00\n",
            "[1747407411] Step 746/1692: training loss=0.00\n",
            "[1747407411] Step 747/1692: training loss=0.88\n",
            "[1747407414] Step 748/1692: training loss=0.00\n",
            "[1747407414] Step 749/1692: training loss=0.00\n",
            "[1747407417] Step 750/1692: training loss=1.06\n",
            "📌 Estado actual: running\n",
            "[1747407417] Step 751/1692: training loss=0.00\n",
            "[1747407420] Step 752/1692: training loss=0.00\n",
            "[1747407420] Step 753/1692: training loss=0.00\n",
            "[1747407422] Step 754/1692: training loss=0.87\n",
            "[1747407423] Step 755/1692: training loss=0.90\n",
            "[1747407425] Step 756/1692: training loss=0.23\n",
            "[1747407425] Step 757/1692: training loss=0.00\n",
            "[1747407428] Step 758/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407428] Step 759/1692: training loss=0.00\n",
            "[1747407431] Step 760/1692: training loss=0.00\n",
            "[1747407431] Step 761/1692: training loss=0.00\n",
            "[1747407434] Step 762/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407434] Step 763/1692: training loss=0.00\n",
            "[1747407436] Step 764/1692: training loss=0.00\n",
            "[1747407436] Step 765/1692: training loss=0.00\n",
            "[1747407439] Step 766/1692: training loss=0.00\n",
            "[1747407440] Step 767/1692: training loss=0.00\n",
            "[1747407442] Step 768/1692: training loss=0.00\n",
            "[1747407442] Step 769/1692: training loss=0.00\n",
            "[1747407445] Step 770/1692: training loss=0.75\n",
            "📌 Estado actual: running\n",
            "[1747407445] Step 771/1692: training loss=0.00\n",
            "[1747407448] Step 772/1692: training loss=0.83\n",
            "[1747407448] Step 773/1692: training loss=0.00\n",
            "[1747407451] Step 774/1692: training loss=0.00\n",
            "[1747407451] Step 775/1692: training loss=0.00\n",
            "[1747407453] Step 776/1692: training loss=0.00\n",
            "[1747407453] Step 777/1692: training loss=0.00\n",
            "[1747407456] Step 778/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407456] Step 779/1692: training loss=0.00\n",
            "[1747407459] Step 780/1692: training loss=0.00\n",
            "[1747407462] Step 781/1692: training loss=2.19\n",
            "[1747407462] Step 782/1692: training loss=0.31\n",
            "[1747407465] Step 783/1692: training loss=0.00\n",
            "[1747407465] Step 784/1692: training loss=0.00\n",
            "[1747407465] Step 785/1692: training loss=0.00\n",
            "[1747407467] Step 786/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407470] Step 787/1692: training loss=0.62\n",
            "[1747407470] Step 788/1692: training loss=0.00\n",
            "[1747407470] Step 789/1692: training loss=0.00\n",
            "[1747407473] Step 790/1692: training loss=0.00\n",
            "[1747407476] Step 791/1692: training loss=0.47\n",
            "[1747407476] Step 792/1692: training loss=0.00\n",
            "[1747407479] Step 793/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407479] Step 794/1692: training loss=0.92\n",
            "[1747407481] Step 795/1692: training loss=0.00\n",
            "[1747407481] Step 796/1692: training loss=0.00\n",
            "[1747407484] Step 797/1692: training loss=0.16\n",
            "[1747407484] Step 798/1692: training loss=0.67\n",
            "[1747407487] Step 799/1692: training loss=0.00\n",
            "[1747407487] Step 800/1692: training loss=0.00\n",
            "[1747407490] Step 801/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407490] Step 802/1692: training loss=0.15\n",
            "[1747407493] Step 803/1692: training loss=0.00\n",
            "[1747407493] Step 804/1692: training loss=0.00\n",
            "[1747407495] Step 805/1692: training loss=0.00\n",
            "[1747407495] Step 806/1692: training loss=0.00\n",
            "[1747407498] Step 807/1692: training loss=0.97\n",
            "[1747407498] Step 808/1692: training loss=0.00\n",
            "[1747407501] Step 809/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407501] Step 810/1692: training loss=0.65\n",
            "[1747407504] Step 811/1692: training loss=0.41\n",
            "[1747407504] Step 812/1692: training loss=0.00\n",
            "[1747407507] Step 813/1692: training loss=0.77\n",
            "[1747407507] Step 814/1692: training loss=0.00\n",
            "[1747407509] Step 815/1692: training loss=0.00\n",
            "[1747407509] Step 816/1692: training loss=0.00\n",
            "[1747407512] Step 817/1692: training loss=0.48\n",
            "📌 Estado actual: running\n",
            "[1747407512] Step 818/1692: training loss=0.43\n",
            "[1747407515] Step 819/1692: training loss=0.00\n",
            "[1747407515] Step 820/1692: training loss=0.01\n",
            "[1747407518] Step 821/1692: training loss=0.00\n",
            "[1747407518] Step 822/1692: training loss=0.00\n",
            "[1747407521] Step 823/1692: training loss=0.00\n",
            "[1747407521] Step 824/1692: training loss=0.00\n",
            "[1747407523] Step 825/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407523] Step 826/1692: training loss=0.00\n",
            "[1747407526] Step 827/1692: training loss=0.00\n",
            "[1747407526] Step 828/1692: training loss=0.44\n",
            "[1747407529] Step 829/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407529] Step 830/1692: training loss=0.00\n",
            "[1747407532] Step 831/1692: training loss=0.00\n",
            "[1747407532] Step 832/1692: training loss=0.00\n",
            "[1747407535] Step 833/1692: training loss=0.00\n",
            "[1747407535] Step 834/1692: training loss=0.68\n",
            "[1747407537] Step 835/1692: training loss=0.00\n",
            "[1747407537] Step 836/1692: training loss=0.00\n",
            "[1747407540] Step 837/1692: training loss=0.47\n",
            "📌 Estado actual: running\n",
            "[1747407540] Step 838/1692: training loss=0.00\n",
            "[1747407543] Step 839/1692: training loss=0.00\n",
            "[1747407543] Step 840/1692: training loss=0.00\n",
            "[1747407546] Step 841/1692: training loss=0.50\n",
            "[1747407546] Step 842/1692: training loss=0.79\n",
            "[1747407549] Step 843/1692: training loss=0.85\n",
            "[1747407549] Step 844/1692: training loss=0.00\n",
            "[1747407551] Step 845/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407551] Step 846/1692: training loss=0.00\n",
            "[1747407554] Step 847/1692: training loss=0.00\n",
            "[1747407554] Step 848/1692: training loss=0.00\n",
            "[1747407557] Step 849/1692: training loss=0.00\n",
            "[1747407560] Step 850/1692: training loss=0.00\n",
            "[1747407560] Step 851/1692: training loss=0.00\n",
            "[1747407563] Step 852/1692: training loss=0.39\n",
            "📌 Estado actual: running\n",
            "[1747407563] Step 853/1692: training loss=0.00\n",
            "[1747407563] Step 854/1692: training loss=0.00\n",
            "[1747407565] Step 855/1692: training loss=0.00\n",
            "[1747407565] Step 856/1692: training loss=0.00\n",
            "[1747407568] Step 857/1692: training loss=0.00\n",
            "[1747407568] Step 858/1692: training loss=0.00\n",
            "[1747407571] Step 859/1692: training loss=0.00\n",
            "[1747407574] Step 860/1692: training loss=0.85\n",
            "📌 Estado actual: running\n",
            "[1747407574] Step 861/1692: training loss=0.00\n",
            "[1747407577] Step 862/1692: training loss=0.00\n",
            "[1747407577] Step 863/1692: training loss=0.00\n",
            "[1747407579] Step 864/1692: training loss=0.00\n",
            "[1747407579] Step 865/1692: training loss=0.00\n",
            "[1747407583] Step 866/1692: training loss=0.00\n",
            "[1747407583] Step 867/1692: training loss=0.00\n",
            "[1747407583] Step 868/1692: training loss=0.00\n",
            "[1747407586] Step 869/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407586] Step 870/1692: training loss=0.00\n",
            "[1747407589] Step 871/1692: training loss=0.67\n",
            "[1747407589] Step 872/1692: training loss=0.00\n",
            "[1747407591] Step 873/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407591] Step 874/1692: training loss=0.00\n",
            "[1747407594] Step 875/1692: training loss=0.00\n",
            "[1747407594] Step 876/1692: training loss=0.00\n",
            "[1747407597] Step 877/1692: training loss=0.00\n",
            "[1747407597] Step 878/1692: training loss=0.00\n",
            "[1747407600] Step 879/1692: training loss=0.00\n",
            "[1747407600] Step 880/1692: training loss=0.00\n",
            "[1747407603] Step 881/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407603] Step 882/1692: training loss=0.00\n",
            "[1747407606] Step 883/1692: training loss=0.02\n",
            "[1747407606] Step 884/1692: training loss=0.00\n",
            "[1747407608] Step 885/1692: training loss=0.79\n",
            "[1747407608] Step 886/1692: training loss=0.00\n",
            "[1747407611] Step 887/1692: training loss=0.00\n",
            "[1747407611] Step 888/1692: training loss=0.00\n",
            "[1747407614] Step 889/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407614] Step 890/1692: training loss=0.02\n",
            "[1747407617] Step 891/1692: training loss=0.00\n",
            "[1747407617] Step 892/1692: training loss=0.00\n",
            "[1747407619] Step 893/1692: training loss=0.00\n",
            "[1747407619] Step 894/1692: training loss=0.98\n",
            "[1747407622] Step 895/1692: training loss=0.00\n",
            "[1747407622] Step 896/1692: training loss=0.00\n",
            "[1747407625] Step 897/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407625] Step 898/1692: training loss=0.00\n",
            "[1747407628] Step 899/1692: training loss=0.00\n",
            "[1747407631] Step 900/1692: training loss=0.83\n",
            "[1747407631] Step 901/1692: training loss=0.00\n",
            "[1747407631] Step 902/1692: training loss=1.38\n",
            "[1747407634] Step 903/1692: training loss=0.00\n",
            "[1747407634] Step 904/1692: training loss=0.88\n",
            "[1747407636] Step 905/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407639] Step 906/1692: training loss=0.50\n",
            "[1747407639] Step 907/1692: training loss=0.00\n",
            "[1747407642] Step 908/1692: training loss=0.00\n",
            "[1747407642] Step 909/1692: training loss=0.88\n",
            "[1747407645] Step 910/1692: training loss=0.00\n",
            "[1747407645] Step 911/1692: training loss=0.57\n",
            "[1747407647] Step 912/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407648] Step 913/1692: training loss=0.00\n",
            "[1747407650] Step 914/1692: training loss=0.00\n",
            "[1747407650] Step 915/1692: training loss=0.00\n",
            "[1747407653] Step 916/1692: training loss=0.00\n",
            "[1747407653] Step 917/1692: training loss=0.00\n",
            "[1747407656] Step 918/1692: training loss=0.77\n",
            "[1747407656] Step 919/1692: training loss=0.00\n",
            "[1747407659] Step 920/1692: training loss=0.76\n",
            "📌 Estado actual: running\n",
            "[1747407659] Step 921/1692: training loss=0.73\n",
            "[1747407662] Step 922/1692: training loss=0.00\n",
            "[1747407662] Step 923/1692: training loss=0.00\n",
            "[1747407664] Step 924/1692: training loss=0.41\n",
            "[1747407664] Step 925/1692: training loss=0.00\n",
            "[1747407667] Step 926/1692: training loss=0.00\n",
            "[1747407667] Step 927/1692: training loss=0.00\n",
            "[1747407670] Step 928/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407670] Step 929/1692: training loss=0.00\n",
            "[1747407673] Step 930/1692: training loss=0.00\n",
            "[1747407673] Step 931/1692: training loss=0.00\n",
            "[1747407675] Step 932/1692: training loss=0.00\n",
            "[1747407676] Step 933/1692: training loss=0.71\n",
            "[1747407678] Step 934/1692: training loss=0.83\n",
            "[1747407678] Step 935/1692: training loss=0.00\n",
            "[1747407681] Step 936/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407681] Step 937/1692: training loss=0.00\n",
            "[1747407684] Step 938/1692: training loss=0.53\n",
            "[1747407684] Step 939/1692: training loss=0.76\n",
            "[1747407687] Step 940/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407687] Step 941/1692: training loss=0.00\n",
            "[1747407690] Step 942/1692: training loss=0.00\n",
            "[1747407690] Step 943/1692: training loss=0.00\n",
            "[1747407692] Step 944/1692: training loss=0.91\n",
            "[1747407692] Step 945/1692: training loss=0.68\n",
            "[1747407695] Step 946/1692: training loss=0.78\n",
            "[1747407695] Step 947/1692: training loss=0.00\n",
            "[1747407698] Step 948/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407698] Step 949/1692: training loss=0.00\n",
            "[1747407701] Step 950/1692: training loss=0.00\n",
            "[1747407701] Step 951/1692: training loss=0.00\n",
            "[1747407703] Step 952/1692: training loss=0.00\n",
            "[1747407704] Step 953/1692: training loss=0.00\n",
            "[1747407706] Step 954/1692: training loss=0.00\n",
            "[1747407706] Step 955/1692: training loss=0.00\n",
            "[1747407709] Step 956/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407709] Step 957/1692: training loss=0.00\n",
            "[1747407712] Step 958/1692: training loss=0.00\n",
            "[1747407712] Step 959/1692: training loss=0.46\n",
            "[1747407714] Step 960/1692: training loss=0.00\n",
            "[1747407715] Step 961/1692: training loss=0.24\n",
            "[1747407718] Step 962/1692: training loss=0.00\n",
            "[1747407718] Step 963/1692: training loss=0.00\n",
            "[1747407720] Step 964/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407720] Step 965/1692: training loss=0.00\n",
            "[1747407723] Step 966/1692: training loss=0.00\n",
            "[1747407723] Step 967/1692: training loss=0.00\n",
            "[1747407726] Step 968/1692: training loss=0.00\n",
            "[1747407726] Step 969/1692: training loss=0.00\n",
            "[1747407729] Step 970/1692: training loss=0.00\n",
            "[1747407729] Step 971/1692: training loss=1.06\n",
            "[1747407731] Step 972/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407734] Step 973/1692: training loss=0.72\n",
            "[1747407734] Step 974/1692: training loss=0.00\n",
            "[1747407737] Step 975/1692: training loss=0.00\n",
            "[1747407737] Step 976/1692: training loss=0.00\n",
            "[1747407740] Step 977/1692: training loss=0.00\n",
            "[1747407740] Step 978/1692: training loss=0.56\n",
            "[1747407742] Step 979/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407743] Step 980/1692: training loss=0.00\n",
            "[1747407745] Step 981/1692: training loss=0.00\n",
            "[1747407745] Step 982/1692: training loss=0.00\n",
            "[1747407748] Step 983/1692: training loss=0.00\n",
            "[1747407748] Step 984/1692: training loss=0.00\n",
            "[1747407751] Step 985/1692: training loss=1.69\n",
            "[1747407751] Step 986/1692: training loss=0.00\n",
            "[1747407754] Step 987/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407754] Step 988/1692: training loss=0.92\n",
            "[1747407757] Step 989/1692: training loss=0.00\n",
            "[1747407757] Step 990/1692: training loss=0.92\n",
            "[1747407759] Step 991/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407760] Step 992/1692: training loss=0.00\n",
            "[1747407762] Step 993/1692: training loss=0.00\n",
            "[1747407762] Step 994/1692: training loss=0.00\n",
            "[1747407765] Step 995/1692: training loss=1.38\n",
            "[1747407765] Step 996/1692: training loss=0.00\n",
            "[1747407768] Step 997/1692: training loss=0.00\n",
            "[1747407768] Step 998/1692: training loss=0.00\n",
            "[1747407770] Step 999/1692: training loss=0.14\n",
            "[1747407771] Step 1000/1692: training loss=0.00\n",
            "[1747407773] Step 1001/1692: training loss=0.50\n",
            "[1747407773] Step 1002/1692: training loss=0.00\n",
            "[1747407776] Step 1003/1692: training loss=0.81\n",
            "📌 Estado actual: running\n",
            "[1747407776] Step 1004/1692: training loss=0.69\n",
            "[1747407779] Step 1005/1692: training loss=0.00\n",
            "[1747407779] Step 1006/1692: training loss=0.00\n",
            "[1747407782] Step 1007/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407782] Step 1008/1692: training loss=0.00\n",
            "[1747407785] Step 1009/1692: training loss=0.00\n",
            "[1747407785] Step 1010/1692: training loss=0.50\n",
            "[1747407787] Step 1011/1692: training loss=0.00\n",
            "[1747407788] Step 1012/1692: training loss=0.40\n",
            "[1747407790] Step 1013/1692: training loss=0.00\n",
            "[1747407790] Step 1014/1692: training loss=0.00\n",
            "[1747407793] Step 1015/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407796] Step 1016/1692: training loss=0.00\n",
            "[1747407796] Step 1017/1692: training loss=0.15\n",
            "[1747407798] Step 1018/1692: training loss=0.00\n",
            "[1747407799] Step 1019/1692: training loss=0.00\n",
            "[1747407801] Step 1020/1692: training loss=0.23\n",
            "[1747407801] Step 1021/1692: training loss=0.00\n",
            "[1747407804] Step 1022/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407804] Step 1023/1692: training loss=0.03\n",
            "[1747407807] Step 1024/1692: training loss=0.00\n",
            "[1747407807] Step 1025/1692: training loss=0.00\n",
            "[1747407810] Step 1026/1692: training loss=0.00\n",
            "[1747407810] Step 1027/1692: training loss=0.00\n",
            "[1747407813] Step 1028/1692: training loss=0.00\n",
            "[1747407813] Step 1029/1692: training loss=0.00\n",
            "[1747407815] Step 1030/1692: training loss=0.88\n",
            "📌 Estado actual: running\n",
            "[1747407816] Step 1031/1692: training loss=0.00\n",
            "[1747407818] Step 1032/1692: training loss=0.00\n",
            "[1747407818] Step 1033/1692: training loss=0.00\n",
            "[1747407821] Step 1034/1692: training loss=0.00\n",
            "[1747407821] Step 1035/1692: training loss=0.00\n",
            "[1747407824] Step 1036/1692: training loss=0.00\n",
            "[1747407824] Step 1037/1692: training loss=0.00\n",
            "[1747407826] Step 1038/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407827] Step 1039/1692: training loss=1.14\n",
            "[1747407829] Step 1040/1692: training loss=0.00\n",
            "[1747407829] Step 1041/1692: training loss=0.00\n",
            "[1747407832] Step 1042/1692: training loss=0.88\n",
            "[1747407832] Step 1043/1692: training loss=0.00\n",
            "[1747407835] Step 1044/1692: training loss=0.00\n",
            "[1747407835] Step 1045/1692: training loss=0.00\n",
            "[1747407838] Step 1046/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407838] Step 1047/1692: training loss=1.35\n",
            "[1747407841] Step 1048/1692: training loss=0.00\n",
            "[1747407841] Step 1049/1692: training loss=0.00\n",
            "[1747407843] Step 1050/1692: training loss=0.00\n",
            "[1747407844] Step 1051/1692: training loss=0.92\n",
            "[1747407846] Step 1052/1692: training loss=0.00\n",
            "[1747407846] Step 1053/1692: training loss=0.00\n",
            "[1747407849] Step 1054/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407849] Step 1055/1692: training loss=0.00\n",
            "[1747407852] Step 1056/1692: training loss=0.00\n",
            "[1747407852] Step 1057/1692: training loss=0.00\n",
            "[1747407854] Step 1058/1692: training loss=0.00\n",
            "[1747407855] Step 1059/1692: training loss=0.76\n",
            "[1747407857] Step 1060/1692: training loss=0.00\n",
            "[1747407857] Step 1061/1692: training loss=0.00\n",
            "[1747407860] Step 1062/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407860] Step 1063/1692: training loss=0.00\n",
            "[1747407863] Step 1064/1692: training loss=0.00\n",
            "[1747407863] Step 1065/1692: training loss=0.00\n",
            "[1747407866] Step 1066/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407868] Step 1067/1692: training loss=0.00\n",
            "[1747407868] Step 1068/1692: training loss=0.00\n",
            "[1747407871] Step 1069/1692: training loss=0.00\n",
            "[1747407871] Step 1070/1692: training loss=0.00\n",
            "[1747407874] Step 1071/1692: training loss=0.00\n",
            "[1747407874] Step 1072/1692: training loss=0.00\n",
            "[1747407877] Step 1073/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407877] Step 1074/1692: training loss=0.00\n",
            "[1747407877] Step 1075/1692: training loss=0.00\n",
            "[1747407880] Step 1076/1692: training loss=0.00\n",
            "[1747407882] Step 1077/1692: training loss=0.00\n",
            "[1747407883] Step 1078/1692: training loss=0.00\n",
            "[1747407885] Step 1079/1692: training loss=0.00\n",
            "[1747407885] Step 1080/1692: training loss=0.00\n",
            "[1747407888] Step 1081/1692: training loss=0.58\n",
            "📌 Estado actual: running\n",
            "[1747407888] Step 1082/1692: training loss=0.00\n",
            "[1747407891] Step 1083/1692: training loss=0.00\n",
            "[1747407891] Step 1084/1692: training loss=0.00\n",
            "[1747407894] Step 1085/1692: training loss=0.82\n",
            "[1747407894] Step 1086/1692: training loss=0.00\n",
            "[1747407896] Step 1087/1692: training loss=0.00\n",
            "[1747407896] Step 1088/1692: training loss=0.00\n",
            "[1747407899] Step 1089/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407899] Step 1090/1692: training loss=0.76\n",
            "[1747407902] Step 1091/1692: training loss=0.00\n",
            "[1747407902] Step 1092/1692: training loss=0.00\n",
            "[1747407905] Step 1093/1692: training loss=0.64\n",
            "[1747407905] Step 1094/1692: training loss=0.00\n",
            "[1747407908] Step 1095/1692: training loss=0.00\n",
            "[1747407908] Step 1096/1692: training loss=0.87\n",
            "[1747407910] Step 1097/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407911] Step 1098/1692: training loss=0.00\n",
            "[1747407913] Step 1099/1692: training loss=0.00\n",
            "[1747407913] Step 1100/1692: training loss=0.00\n",
            "[1747407916] Step 1101/1692: training loss=0.00\n",
            "[1747407916] Step 1102/1692: training loss=0.00\n",
            "[1747407919] Step 1103/1692: training loss=0.00\n",
            "[1747407919] Step 1104/1692: training loss=0.00\n",
            "[1747407922] Step 1105/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407922] Step 1106/1692: training loss=0.00\n",
            "[1747407924] Step 1107/1692: training loss=0.00\n",
            "[1747407924] Step 1108/1692: training loss=0.00\n",
            "[1747407927] Step 1109/1692: training loss=0.00\n",
            "[1747407927] Step 1110/1692: training loss=0.00\n",
            "[1747407930] Step 1111/1692: training loss=0.71\n",
            "[1747407930] Step 1112/1692: training loss=0.00\n",
            "[1747407933] Step 1113/1692: training loss=0.29\n",
            "📌 Estado actual: running\n",
            "[1747407933] Step 1114/1692: training loss=0.00\n",
            "[1747407936] Step 1115/1692: training loss=0.00\n",
            "[1747407936] Step 1116/1692: training loss=0.00\n",
            "[1747407938] Step 1117/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407941] Step 1118/1692: training loss=0.00\n",
            "[1747407941] Step 1119/1692: training loss=0.00\n",
            "[1747407944] Step 1120/1692: training loss=0.00\n",
            "[1747407944] Step 1121/1692: training loss=0.00\n",
            "[1747407947] Step 1122/1692: training loss=0.00\n",
            "[1747407947] Step 1123/1692: training loss=0.00\n",
            "[1747407950] Step 1124/1692: training loss=0.95\n",
            "📌 Estado actual: running\n",
            "[1747407950] Step 1125/1692: training loss=0.00\n",
            "[1747407952] Step 1126/1692: training loss=0.00\n",
            "[1747407952] Step 1127/1692: training loss=0.00\n",
            "[1747407955] Step 1128/1692: training loss=0.00\n",
            "[1747407958] Step 1129/1692: training loss=0.70\n",
            "[1747407958] Step 1130/1692: training loss=0.00\n",
            "[1747407961] Step 1131/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407961] Step 1132/1692: training loss=0.00\n",
            "[1747407964] Step 1133/1692: training loss=0.00\n",
            "[1747407964] Step 1134/1692: training loss=0.00\n",
            "[1747407967] Step 1135/1692: training loss=0.00\n",
            "[1747407967] Step 1136/1692: training loss=0.00\n",
            "[1747407970] Step 1137/1692: training loss=0.00\n",
            "[1747407970] Step 1138/1692: training loss=0.88\n",
            "[1747407972] Step 1139/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407972] Step 1140/1692: training loss=0.28\n",
            "[1747407975] Step 1141/1692: training loss=0.00\n",
            "[1747407975] Step 1142/1692: training loss=0.00\n",
            "[1747407978] Step 1143/1692: training loss=0.00\n",
            "[1747407978] Step 1144/1692: training loss=0.00\n",
            "[1747407981] Step 1145/1692: training loss=0.00\n",
            "[1747407981] Step 1146/1692: training loss=0.00\n",
            "[1747407983] Step 1147/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407984] Step 1148/1692: training loss=0.00\n",
            "[1747407986] Step 1149/1692: training loss=0.00\n",
            "[1747407989] Step 1150/1692: training loss=0.00\n",
            "[1747407989] Step 1151/1692: training loss=0.78\n",
            "[1747407992] Step 1152/1692: training loss=0.00\n",
            "[1747407992] Step 1153/1692: training loss=0.74\n",
            "[1747407992] Step 1154/1692: training loss=0.00\n",
            "[1747407995] Step 1155/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747407995] Step 1156/1692: training loss=0.60\n",
            "[1747407998] Step 1157/1692: training loss=0.00\n",
            "[1747407998] Step 1158/1692: training loss=0.00\n",
            "[1747408000] Step 1159/1692: training loss=0.00\n",
            "[1747408003] Step 1160/1692: training loss=0.00\n",
            "[1747408004] Step 1161/1692: training loss=0.87\n",
            "[1747408006] Step 1162/1692: training loss=0.72\n",
            "📌 Estado actual: running\n",
            "[1747408006] Step 1163/1692: training loss=0.00\n",
            "[1747408009] Step 1164/1692: training loss=0.00\n",
            "[1747408009] Step 1165/1692: training loss=0.75\n",
            "[1747408009] Step 1166/1692: training loss=0.00\n",
            "[1747408012] Step 1167/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408015] Step 1168/1692: training loss=0.00\n",
            "[1747408015] Step 1169/1692: training loss=0.00\n",
            "[1747408017] Step 1170/1692: training loss=0.00\n",
            "[1747408018] Step 1171/1692: training loss=0.75\n",
            "[1747408020] Step 1172/1692: training loss=0.74\n",
            "[1747408020] Step 1173/1692: training loss=0.00\n",
            "[1747408023] Step 1174/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408023] Step 1175/1692: training loss=0.00\n",
            "[1747408026] Step 1176/1692: training loss=0.00\n",
            "[1747408026] Step 1177/1692: training loss=0.00\n",
            "[1747408029] Step 1178/1692: training loss=0.00\n",
            "[1747408029] Step 1179/1692: training loss=0.00\n",
            "[1747408029] Step 1180/1692: training loss=0.00\n",
            "[1747408032] Step 1181/1692: training loss=0.00\n",
            "[1747408034] Step 1182/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408035] Step 1183/1692: training loss=0.00\n",
            "[1747408037] Step 1184/1692: training loss=0.00\n",
            "[1747408037] Step 1185/1692: training loss=0.00\n",
            "[1747408040] Step 1186/1692: training loss=0.00\n",
            "[1747408040] Step 1187/1692: training loss=0.00\n",
            "[1747408043] Step 1188/1692: training loss=0.74\n",
            "[1747408043] Step 1189/1692: training loss=0.00\n",
            "[1747408045] Step 1190/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "📌 Estado actual: running\n",
            "[1747408062] Step 1191/1692: training loss=0.00\n",
            "[1747408065] Step 1192/1692: training loss=0.00\n",
            "[1747408065] Step 1193/1692: training loss=0.00\n",
            "[1747408065] Step 1194/1692: training loss=0.00\n",
            "[1747408067] Step 1195/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408070] Step 1196/1692: training loss=0.00\n",
            "[1747408070] Step 1197/1692: training loss=0.00\n",
            "[1747408073] Step 1198/1692: training loss=0.00\n",
            "[1747408073] Step 1199/1692: training loss=0.00\n",
            "[1747408076] Step 1200/1692: training loss=0.00\n",
            "[1747408076] Step 1201/1692: training loss=0.00\n",
            "[1747408079] Step 1202/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408079] Step 1203/1692: training loss=0.00\n",
            "[1747408081] Step 1204/1692: training loss=0.00\n",
            "[1747408081] Step 1205/1692: training loss=0.00\n",
            "[1747408084] Step 1206/1692: training loss=0.00\n",
            "[1747408084] Step 1207/1692: training loss=0.00\n",
            "[1747408087] Step 1208/1692: training loss=0.00\n",
            "[1747408087] Step 1209/1692: training loss=0.00\n",
            "[1747408090] Step 1210/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408090] Step 1211/1692: training loss=0.00\n",
            "[1747408093] Step 1212/1692: training loss=0.00\n",
            "[1747408093] Step 1213/1692: training loss=0.00\n",
            "[1747408096] Step 1214/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408096] Step 1215/1692: training loss=0.00\n",
            "[1747408098] Step 1216/1692: training loss=0.00\n",
            "[1747408098] Step 1217/1692: training loss=0.91\n",
            "[1747408101] Step 1218/1692: training loss=0.00\n",
            "[1747408101] Step 1219/1692: training loss=0.00\n",
            "[1747408104] Step 1220/1692: training loss=0.00\n",
            "[1747408104] Step 1221/1692: training loss=0.00\n",
            "[1747408107] Step 1222/1692: training loss=0.91\n",
            "📌 Estado actual: running\n",
            "[1747408107] Step 1223/1692: training loss=0.00\n",
            "[1747408109] Step 1224/1692: training loss=0.00\n",
            "[1747408109] Step 1225/1692: training loss=0.00\n",
            "[1747408112] Step 1226/1692: training loss=0.00\n",
            "[1747408112] Step 1227/1692: training loss=0.00\n",
            "[1747408116] Step 1228/1692: training loss=0.77\n",
            "[1747408116] Step 1229/1692: training loss=0.00\n",
            "[1747408119] Step 1230/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408119] Step 1231/1692: training loss=0.00\n",
            "[1747408122] Step 1232/1692: training loss=0.00\n",
            "[1747408122] Step 1233/1692: training loss=0.00\n",
            "[1747408124] Step 1234/1692: training loss=0.00\n",
            "[1747408125] Step 1235/1692: training loss=0.00\n",
            "[1747408127] Step 1236/1692: training loss=0.00\n",
            "[1747408127] Step 1237/1692: training loss=0.00\n",
            "[1747408130] Step 1238/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408130] Step 1239/1692: training loss=0.00\n",
            "[1747408133] Step 1240/1692: training loss=0.00\n",
            "[1747408133] Step 1241/1692: training loss=0.00\n",
            "[1747408136] Step 1242/1692: training loss=0.00\n",
            "[1747408136] Step 1243/1692: training loss=0.00\n",
            "[1747408138] Step 1244/1692: training loss=0.00\n",
            "[1747408138] Step 1245/1692: training loss=0.00\n",
            "[1747408141] Step 1246/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408141] Step 1247/1692: training loss=0.82\n",
            "[1747408144] Step 1248/1692: training loss=0.00\n",
            "[1747408144] Step 1249/1692: training loss=0.00\n",
            "[1747408147] Step 1250/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408147] Step 1251/1692: training loss=0.00\n",
            "[1747408150] Step 1252/1692: training loss=0.00\n",
            "[1747408150] Step 1253/1692: training loss=0.00\n",
            "[1747408153] Step 1254/1692: training loss=0.00\n",
            "[1747408153] Step 1255/1692: training loss=0.00\n",
            "[1747408155] Step 1256/1692: training loss=0.00\n",
            "[1747408155] Step 1257/1692: training loss=0.00\n",
            "[1747408161] Step 1258/1692: training loss=1.03\n",
            "📌 Estado actual: running\n",
            "[1747408161] Step 1259/1692: training loss=0.00\n",
            "[1747408164] Step 1260/1692: training loss=0.00\n",
            "[1747408164] Step 1261/1692: training loss=0.00\n",
            "[1747408166] Step 1262/1692: training loss=0.81\n",
            "[1747408169] Step 1263/1692: training loss=0.00\n",
            "[1747408169] Step 1264/1692: training loss=0.00\n",
            "[1747408172] Step 1265/1692: training loss=0.70\n",
            "📌 Estado actual: running\n",
            "[1747408172] Step 1266/1692: training loss=0.00\n",
            "[1747408175] Step 1267/1692: training loss=0.00\n",
            "[1747408175] Step 1268/1692: training loss=0.00\n",
            "[1747408177] Step 1269/1692: training loss=0.84\n",
            "[1747408178] Step 1270/1692: training loss=0.00\n",
            "[1747408181] Step 1271/1692: training loss=0.00\n",
            "[1747408181] Step 1272/1692: training loss=0.00\n",
            "[1747408183] Step 1273/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408183] Step 1274/1692: training loss=0.00\n",
            "[1747408186] Step 1275/1692: training loss=0.00\n",
            "[1747408186] Step 1276/1692: training loss=0.00\n",
            "[1747408189] Step 1277/1692: training loss=0.85\n",
            "📌 Estado actual: running\n",
            "[1747408189] Step 1278/1692: training loss=0.37\n",
            "[1747408192] Step 1279/1692: training loss=0.00\n",
            "[1747408192] Step 1280/1692: training loss=0.00\n",
            "[1747408194] Step 1281/1692: training loss=0.00\n",
            "[1747408195] Step 1282/1692: training loss=0.00\n",
            "[1747408197] Step 1283/1692: training loss=0.00\n",
            "[1747408197] Step 1284/1692: training loss=0.00\n",
            "[1747408200] Step 1285/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408200] Step 1286/1692: training loss=0.00\n",
            "[1747408203] Step 1287/1692: training loss=0.00\n",
            "[1747408203] Step 1288/1692: training loss=0.00\n",
            "[1747408205] Step 1289/1692: training loss=0.00\n",
            "[1747408206] Step 1290/1692: training loss=0.00\n",
            "[1747408208] Step 1291/1692: training loss=0.00\n",
            "[1747408208] Step 1292/1692: training loss=0.00\n",
            "[1747408211] Step 1293/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408211] Step 1294/1692: training loss=0.00\n",
            "[1747408214] Step 1295/1692: training loss=0.00\n",
            "[1747408214] Step 1296/1692: training loss=0.00\n",
            "[1747408217] Step 1297/1692: training loss=0.00\n",
            "[1747408217] Step 1298/1692: training loss=0.00\n",
            "[1747408220] Step 1299/1692: training loss=0.00\n",
            "[1747408220] Step 1300/1692: training loss=0.00\n",
            "[1747408222] Step 1301/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408223] Step 1302/1692: training loss=0.00\n",
            "[1747408225] Step 1303/1692: training loss=0.00\n",
            "[1747408225] Step 1304/1692: training loss=0.85\n",
            "[1747408228] Step 1305/1692: training loss=0.00\n",
            "[1747408228] Step 1306/1692: training loss=0.00\n",
            "[1747408231] Step 1307/1692: training loss=0.97\n",
            "[1747408231] Step 1308/1692: training loss=0.64\n",
            "[1747408233] Step 1309/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408234] Step 1310/1692: training loss=0.00\n",
            "[1747408236] Step 1311/1692: training loss=0.67\n",
            "[1747408236] Step 1312/1692: training loss=0.00\n",
            "[1747408239] Step 1313/1692: training loss=0.00\n",
            "[1747408239] Step 1314/1692: training loss=0.00\n",
            "[1747408242] Step 1315/1692: training loss=0.00\n",
            "[1747408242] Step 1316/1692: training loss=0.90\n",
            "[1747408245] Step 1317/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408245] Step 1318/1692: training loss=0.82\n",
            "[1747408248] Step 1319/1692: training loss=0.00\n",
            "[1747408248] Step 1320/1692: training loss=0.00\n",
            "[1747408250] Step 1321/1692: training loss=0.00\n",
            "[1747408253] Step 1322/1692: training loss=0.00\n",
            "[1747408253] Step 1323/1692: training loss=0.00\n",
            "[1747408253] Step 1324/1692: training loss=0.00\n",
            "[1747408256] Step 1325/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408259] Step 1326/1692: training loss=0.57\n",
            "[1747408259] Step 1327/1692: training loss=0.00\n",
            "[1747408261] Step 1328/1692: training loss=0.00\n",
            "[1747408262] Step 1329/1692: training loss=0.00\n",
            "[1747408264] Step 1330/1692: training loss=0.00\n",
            "[1747408267] Step 1331/1692: training loss=0.09\n",
            "📌 Estado actual: running\n",
            "[1747408270] Step 1332/1692: training loss=0.85\n",
            "[1747408270] Step 1333/1692: training loss=0.00\n",
            "[1747408273] Step 1334/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408273] Step 1335/1692: training loss=0.00\n",
            "[1747408276] Step 1336/1692: training loss=0.00\n",
            "[1747408276] Step 1337/1692: training loss=0.00\n",
            "[1747408278] Step 1338/1692: training loss=0.00\n",
            "[1747408279] Step 1339/1692: training loss=0.00\n",
            "[1747408281] Step 1340/1692: training loss=0.00\n",
            "[1747408281] Step 1341/1692: training loss=0.26\n",
            "[1747408284] Step 1342/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408284] Step 1343/1692: training loss=0.00\n",
            "[1747408287] Step 1344/1692: training loss=0.96\n",
            "[1747408287] Step 1345/1692: training loss=0.00\n",
            "[1747408290] Step 1346/1692: training loss=0.00\n",
            "[1747408290] Step 1347/1692: training loss=0.00\n",
            "[1747408292] Step 1348/1692: training loss=0.00\n",
            "[1747408292] Step 1349/1692: training loss=0.00\n",
            "[1747408295] Step 1350/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408298] Step 1351/1692: training loss=0.00\n",
            "[1747408298] Step 1352/1692: training loss=0.00\n",
            "[1747408298] Step 1353/1692: training loss=0.00\n",
            "[1747408301] Step 1354/1692: training loss=0.00\n",
            "[1747408304] Step 1355/1692: training loss=0.00\n",
            "[1747408304] Step 1356/1692: training loss=0.00\n",
            "[1747408304] Step 1357/1692: training loss=0.00\n",
            "[1747408306] Step 1358/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408307] Step 1359/1692: training loss=0.00\n",
            "[1747408309] Step 1360/1692: training loss=0.00\n",
            "[1747408309] Step 1361/1692: training loss=0.00\n",
            "[1747408312] Step 1362/1692: training loss=0.67\n",
            "[1747408312] Step 1363/1692: training loss=0.00\n",
            "[1747408315] Step 1364/1692: training loss=0.00\n",
            "[1747408315] Step 1365/1692: training loss=0.00\n",
            "[1747408318] Step 1366/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408318] Step 1367/1692: training loss=0.00\n",
            "[1747408320] Step 1368/1692: training loss=0.00\n",
            "[1747408320] Step 1369/1692: training loss=0.00\n",
            "[1747408323] Step 1370/1692: training loss=0.00\n",
            "[1747408326] Step 1371/1692: training loss=0.00\n",
            "[1747408326] Step 1372/1692: training loss=0.00\n",
            "[1747408329] Step 1373/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408329] Step 1374/1692: training loss=0.00\n",
            "[1747408332] Step 1375/1692: training loss=0.00\n",
            "[1747408332] Step 1376/1692: training loss=0.00\n",
            "[1747408334] Step 1377/1692: training loss=0.00\n",
            "[1747408335] Step 1378/1692: training loss=0.00\n",
            "[1747408337] Step 1379/1692: training loss=0.00\n",
            "[1747408337] Step 1380/1692: training loss=0.00\n",
            "[1747408340] Step 1381/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408340] Step 1382/1692: training loss=0.00\n",
            "[1747408343] Step 1383/1692: training loss=2.82\n",
            "[1747408343] Step 1384/1692: training loss=0.82\n",
            "[1747408346] Step 1385/1692: training loss=0.00\n",
            "[1747408346] Step 1386/1692: training loss=0.73\n",
            "[1747408348] Step 1387/1692: training loss=0.88\n",
            "[1747408348] Step 1388/1692: training loss=0.00\n",
            "[1747408351] Step 1389/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408351] Step 1390/1692: training loss=0.85\n",
            "[1747408354] Step 1391/1692: training loss=0.00\n",
            "[1747408354] Step 1392/1692: training loss=0.00\n",
            "[1747408357] Step 1393/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408357] Step 1394/1692: training loss=0.00\n",
            "[1747408360] Step 1395/1692: training loss=0.00\n",
            "[1747408360] Step 1396/1692: training loss=0.00\n",
            "[1747408362] Step 1397/1692: training loss=0.00\n",
            "[1747408362] Step 1398/1692: training loss=0.00\n",
            "[1747408365] Step 1399/1692: training loss=0.00\n",
            "[1747408365] Step 1400/1692: training loss=0.00\n",
            "[1747408368] Step 1401/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408368] Step 1402/1692: training loss=0.00\n",
            "[1747408371] Step 1403/1692: training loss=0.00\n",
            "[1747408371] Step 1404/1692: training loss=0.55\n",
            "[1747408374] Step 1405/1692: training loss=0.00\n",
            "[1747408374] Step 1406/1692: training loss=0.00\n",
            "[1747408376] Step 1407/1692: training loss=0.00\n",
            "[1747408376] Step 1408/1692: training loss=0.00\n",
            "[1747408379] Step 1409/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408379] Step 1410/1692: training loss=0.64\n",
            "[1747408382] Step 1411/1692: training loss=0.00\n",
            "[1747408382] Step 1412/1692: training loss=0.00\n",
            "[1747408385] Step 1413/1692: training loss=0.00\n",
            "[1747408385] Step 1414/1692: training loss=0.00\n",
            "[1747408388] Step 1415/1692: training loss=0.00\n",
            "[1747408388] Step 1416/1692: training loss=0.00\n",
            "[1747408390] Step 1417/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408390] Step 1418/1692: training loss=0.00\n",
            "[1747408393] Step 1419/1692: training loss=0.00\n",
            "[1747408393] Step 1420/1692: training loss=0.00\n",
            "[1747408396] Step 1421/1692: training loss=0.00\n",
            "[1747408396] Step 1422/1692: training loss=0.00\n",
            "[1747408399] Step 1423/1692: training loss=0.00\n",
            "[1747408399] Step 1424/1692: training loss=0.00\n",
            "[1747408402] Step 1425/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408402] Step 1426/1692: training loss=0.00\n",
            "[1747408405] Step 1427/1692: training loss=0.00\n",
            "[1747408405] Step 1428/1692: training loss=0.00\n",
            "[1747408407] Step 1429/1692: training loss=0.00\n",
            "[1747408407] Step 1430/1692: training loss=0.00\n",
            "[1747408410] Step 1431/1692: training loss=0.99\n",
            "[1747408410] Step 1432/1692: training loss=0.00\n",
            "[1747408413] Step 1433/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408413] Step 1434/1692: training loss=0.00\n",
            "[1747408416] Step 1435/1692: training loss=0.00\n",
            "[1747408418] Step 1436/1692: training loss=0.00\n",
            "[1747408418] Step 1437/1692: training loss=0.00\n",
            "[1747408421] Step 1438/1692: training loss=0.00\n",
            "[1747408421] Step 1439/1692: training loss=0.00\n",
            "[1747408424] Step 1440/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408424] Step 1441/1692: training loss=0.00\n",
            "[1747408427] Step 1442/1692: training loss=0.00\n",
            "[1747408427] Step 1443/1692: training loss=0.00\n",
            "[1747408430] Step 1444/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408430] Step 1445/1692: training loss=0.00\n",
            "[1747408433] Step 1446/1692: training loss=0.00\n",
            "[1747408433] Step 1447/1692: training loss=0.00\n",
            "[1747408435] Step 1448/1692: training loss=0.00\n",
            "[1747408435] Step 1449/1692: training loss=0.00\n",
            "[1747408438] Step 1450/1692: training loss=0.00\n",
            "[1747408438] Step 1451/1692: training loss=0.00\n",
            "[1747408441] Step 1452/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408441] Step 1453/1692: training loss=0.00\n",
            "[1747408444] Step 1454/1692: training loss=0.00\n",
            "[1747408444] Step 1455/1692: training loss=1.22\n",
            "[1747408446] Step 1456/1692: training loss=0.00\n",
            "[1747408447] Step 1457/1692: training loss=0.00\n",
            "[1747408449] Step 1458/1692: training loss=0.00\n",
            "[1747408449] Step 1459/1692: training loss=0.00\n",
            "[1747408452] Step 1460/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408452] Step 1461/1692: training loss=0.00\n",
            "[1747408455] Step 1462/1692: training loss=0.84\n",
            "[1747408455] Step 1463/1692: training loss=0.00\n",
            "[1747408458] Step 1464/1692: training loss=0.00\n",
            "[1747408458] Step 1465/1692: training loss=0.00\n",
            "[1747408461] Step 1466/1692: training loss=0.00\n",
            "[1747408461] Step 1467/1692: training loss=0.00\n",
            "[1747408463] Step 1468/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408464] Step 1469/1692: training loss=0.00\n",
            "[1747408466] Step 1470/1692: training loss=0.00\n",
            "[1747408466] Step 1471/1692: training loss=0.00\n",
            "[1747408469] Step 1472/1692: training loss=0.00\n",
            "[1747408469] Step 1473/1692: training loss=0.00\n",
            "[1747408472] Step 1474/1692: training loss=0.85\n",
            "[1747408472] Step 1475/1692: training loss=0.00\n",
            "[1747408474] Step 1476/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408475] Step 1477/1692: training loss=0.00\n",
            "[1747408477] Step 1478/1692: training loss=0.00\n",
            "[1747408477] Step 1479/1692: training loss=0.00\n",
            "[1747408480] Step 1480/1692: training loss=0.00\n",
            "[1747408483] Step 1481/1692: training loss=0.00\n",
            "[1747408483] Step 1482/1692: training loss=0.00\n",
            "[1747408483] Step 1483/1692: training loss=0.00\n",
            "[1747408486] Step 1484/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408489] Step 1485/1692: training loss=0.00\n",
            "[1747408489] Step 1486/1692: training loss=0.00\n",
            "[1747408489] Step 1487/1692: training loss=0.00\n",
            "[1747408491] Step 1488/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408492] Step 1489/1692: training loss=0.00\n",
            "[1747408494] Step 1490/1692: training loss=0.00\n",
            "[1747408497] Step 1491/1692: training loss=0.00\n",
            "[1747408497] Step 1492/1692: training loss=0.00\n",
            "[1747408497] Step 1493/1692: training loss=0.00\n",
            "[1747408500] Step 1494/1692: training loss=0.00\n",
            "[1747408503] Step 1495/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408503] Step 1496/1692: training loss=0.00\n",
            "[1747408505] Step 1497/1692: training loss=0.81\n",
            "[1747408505] Step 1498/1692: training loss=1.08\n",
            "[1747408508] Step 1499/1692: training loss=0.00\n",
            "[1747408508] Step 1500/1692: training loss=0.00\n",
            "[1747408511] Step 1501/1692: training loss=0.00\n",
            "[1747408511] Step 1502/1692: training loss=0.74\n",
            "[1747408514] Step 1503/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408514] Step 1504/1692: training loss=0.00\n",
            "[1747408516] Step 1505/1692: training loss=0.00\n",
            "[1747408516] Step 1506/1692: training loss=0.00\n",
            "[1747408519] Step 1507/1692: training loss=0.00\n",
            "[1747408520] Step 1508/1692: training loss=0.00\n",
            "[1747408522] Step 1509/1692: training loss=1.01\n",
            "[1747408522] Step 1510/1692: training loss=0.00\n",
            "[1747408525] Step 1511/1692: training loss=0.07\n",
            "📌 Estado actual: running\n",
            "[1747408525] Step 1512/1692: training loss=0.00\n",
            "[1747408528] Step 1513/1692: training loss=1.76\n",
            "[1747408528] Step 1514/1692: training loss=0.00\n",
            "[1747408531] Step 1515/1692: training loss=0.00\n",
            "[1747408531] Step 1516/1692: training loss=0.69\n",
            "[1747408533] Step 1517/1692: training loss=0.00\n",
            "[1747408533] Step 1518/1692: training loss=0.00\n",
            "[1747408536] Step 1519/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408536] Step 1520/1692: training loss=0.00\n",
            "[1747408539] Step 1521/1692: training loss=0.84\n",
            "[1747408539] Step 1522/1692: training loss=0.00\n",
            "[1747408542] Step 1523/1692: training loss=0.00\n",
            "[1747408542] Step 1524/1692: training loss=0.00\n",
            "[1747408545] Step 1525/1692: training loss=0.00\n",
            "[1747408545] Step 1526/1692: training loss=0.00\n",
            "[1747408547] Step 1527/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408547] Step 1528/1692: training loss=0.00\n",
            "[1747408550] Step 1529/1692: training loss=0.00\n",
            "[1747408550] Step 1530/1692: training loss=0.00\n",
            "[1747408553] Step 1531/1692: training loss=0.00\n",
            "[1747408553] Step 1532/1692: training loss=0.97\n",
            "[1747408556] Step 1533/1692: training loss=0.00\n",
            "[1747408556] Step 1534/1692: training loss=0.00\n",
            "[1747408559] Step 1535/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408559] Step 1536/1692: training loss=0.00\n",
            "[1747408561] Step 1537/1692: training loss=0.00\n",
            "[1747408561] Step 1538/1692: training loss=0.00\n",
            "[1747408564] Step 1539/1692: training loss=0.00\n",
            "[1747408567] Step 1540/1692: training loss=0.00\n",
            "[1747408567] Step 1541/1692: training loss=0.65\n",
            "[1747408570] Step 1542/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408570] Step 1543/1692: training loss=0.00\n",
            "[1747408570] Step 1544/1692: training loss=0.00\n",
            "[1747408573] Step 1545/1692: training loss=0.00\n",
            "[1747408575] Step 1546/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408575] Step 1547/1692: training loss=0.00\n",
            "[1747408575] Step 1548/1692: training loss=0.00\n",
            "[1747408578] Step 1549/1692: training loss=0.00\n",
            "[1747408581] Step 1550/1692: training loss=0.00\n",
            "[1747408581] Step 1551/1692: training loss=0.00\n",
            "[1747408584] Step 1552/1692: training loss=0.00\n",
            "[1747408584] Step 1553/1692: training loss=0.00\n",
            "[1747408584] Step 1554/1692: training loss=0.00\n",
            "[1747408587] Step 1555/1692: training loss=0.40\n",
            "📌 Estado actual: running\n",
            "[1747408589] Step 1556/1692: training loss=0.00\n",
            "[1747408589] Step 1557/1692: training loss=0.00\n",
            "[1747408592] Step 1558/1692: training loss=0.00\n",
            "[1747408592] Step 1559/1692: training loss=0.00\n",
            "[1747408595] Step 1560/1692: training loss=0.00\n",
            "[1747408595] Step 1561/1692: training loss=0.00\n",
            "[1747408598] Step 1562/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408598] Step 1563/1692: training loss=1.73\n",
            "[1747408601] Step 1564/1692: training loss=0.00\n",
            "[1747408601] Step 1565/1692: training loss=0.00\n",
            "[1747408603] Step 1566/1692: training loss=0.00\n",
            "[1747408603] Step 1567/1692: training loss=0.87\n",
            "[1747408606] Step 1568/1692: training loss=0.00\n",
            "[1747408606] Step 1569/1692: training loss=0.00\n",
            "[1747408609] Step 1570/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408609] Step 1571/1692: training loss=0.00\n",
            "[1747408612] Step 1572/1692: training loss=0.00\n",
            "[1747408612] Step 1573/1692: training loss=0.00\n",
            "[1747408615] Step 1574/1692: training loss=1.06\n",
            "[1747408615] Step 1575/1692: training loss=0.00\n",
            "[1747408618] Step 1576/1692: training loss=0.00\n",
            "[1747408618] Step 1577/1692: training loss=0.00\n",
            "[1747408620] Step 1578/1692: training loss=0.99\n",
            "📌 Estado actual: running\n",
            "[1747408621] Step 1579/1692: training loss=0.00\n",
            "[1747408623] Step 1580/1692: training loss=0.84\n",
            "[1747408623] Step 1581/1692: training loss=0.02\n",
            "[1747408626] Step 1582/1692: training loss=0.00\n",
            "[1747408626] Step 1583/1692: training loss=0.52\n",
            "[1747408629] Step 1584/1692: training loss=0.00\n",
            "[1747408629] Step 1585/1692: training loss=0.00\n",
            "[1747408632] Step 1586/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408632] Step 1587/1692: training loss=0.00\n",
            "[1747408635] Step 1588/1692: training loss=0.00\n",
            "[1747408635] Step 1589/1692: training loss=0.00\n",
            "[1747408637] Step 1590/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408638] Step 1591/1692: training loss=0.00\n",
            "[1747408640] Step 1592/1692: training loss=0.00\n",
            "[1747408640] Step 1593/1692: training loss=0.00\n",
            "[1747408643] Step 1594/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408643] Step 1595/1692: training loss=0.90\n",
            "[1747408646] Step 1596/1692: training loss=0.00\n",
            "[1747408646] Step 1597/1692: training loss=0.00\n",
            "[1747408657] Step 1598/1692: training loss=0.37\n",
            "[1747408657] Step 1599/1692: training loss=0.00\n",
            "[1747408660] Step 1600/1692: training loss=0.00\n",
            "[1747408662] Step 1601/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408663] Step 1602/1692: training loss=0.00\n",
            "[1747408665] Step 1603/1692: training loss=0.00\n",
            "[1747408665] Step 1604/1692: training loss=0.00\n",
            "[1747408668] Step 1605/1692: training loss=0.00\n",
            "[1747408668] Step 1606/1692: training loss=0.00\n",
            "[1747408671] Step 1607/1692: training loss=0.00\n",
            "[1747408671] Step 1608/1692: training loss=0.00\n",
            "[1747408674] Step 1609/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408674] Step 1610/1692: training loss=1.66\n",
            "[1747408677] Step 1611/1692: training loss=0.00\n",
            "[1747408677] Step 1612/1692: training loss=0.00\n",
            "[1747408679] Step 1613/1692: training loss=0.89\n",
            "📌 Estado actual: running\n",
            "[1747408680] Step 1614/1692: training loss=0.00\n",
            "[1747408682] Step 1615/1692: training loss=0.00\n",
            "[1747408682] Step 1616/1692: training loss=0.00\n",
            "[1747408685] Step 1617/1692: training loss=0.00\n",
            "[1747408685] Step 1618/1692: training loss=0.00\n",
            "[1747408688] Step 1619/1692: training loss=0.00\n",
            "[1747408688] Step 1620/1692: training loss=0.00\n",
            "[1747408691] Step 1621/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408691] Step 1622/1692: training loss=0.00\n",
            "[1747408693] Step 1623/1692: training loss=0.00\n",
            "[1747408693] Step 1624/1692: training loss=0.00\n",
            "[1747408696] Step 1625/1692: training loss=0.00\n",
            "[1747408696] Step 1626/1692: training loss=0.00\n",
            "[1747408699] Step 1627/1692: training loss=0.00\n",
            "[1747408702] Step 1628/1692: training loss=0.43\n",
            "📌 Estado actual: running\n",
            "[1747408705] Step 1629/1692: training loss=0.00\n",
            "[1747408705] Step 1630/1692: training loss=0.00\n",
            "[1747408707] Step 1631/1692: training loss=0.81\n",
            "[1747408708] Step 1632/1692: training loss=0.00\n",
            "[1747408710] Step 1633/1692: training loss=0.86\n",
            "[1747408710] Step 1634/1692: training loss=0.00\n",
            "[1747408713] Step 1635/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408713] Step 1636/1692: training loss=0.90\n",
            "[1747408716] Step 1637/1692: training loss=0.00\n",
            "[1747408716] Step 1638/1692: training loss=0.00\n",
            "[1747408718] Step 1639/1692: training loss=0.00\n",
            "[1747408719] Step 1640/1692: training loss=0.00\n",
            "[1747408721] Step 1641/1692: training loss=0.84\n",
            "[1747408721] Step 1642/1692: training loss=0.00\n",
            "[1747408724] Step 1643/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408724] Step 1644/1692: training loss=0.00\n",
            "[1747408727] Step 1645/1692: training loss=0.00\n",
            "[1747408730] Step 1646/1692: training loss=0.00\n",
            "[1747408730] Step 1647/1692: training loss=0.68\n",
            "[1747408730] Step 1648/1692: training loss=0.00\n",
            "[1747408732] Step 1649/1692: training loss=0.00\n",
            "[1747408732] Step 1650/1692: training loss=0.00\n",
            "[1747408736] Step 1651/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408736] Step 1652/1692: training loss=0.00\n",
            "[1747408738] Step 1653/1692: training loss=0.00\n",
            "[1747408738] Step 1654/1692: training loss=0.00\n",
            "[1747408741] Step 1655/1692: training loss=0.00\n",
            "[1747408741] Step 1656/1692: training loss=0.00\n",
            "[1747408744] Step 1657/1692: training loss=0.00\n",
            "[1747408744] Step 1658/1692: training loss=0.00\n",
            "[1747408747] Step 1659/1692: training loss=0.44\n",
            "📌 Estado actual: running\n",
            "[1747408747] Step 1660/1692: training loss=0.00\n",
            "[1747408750] Step 1661/1692: training loss=0.00\n",
            "[1747408750] Step 1662/1692: training loss=0.00\n",
            "[1747408752] Step 1663/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408752] Step 1664/1692: training loss=0.00\n",
            "[1747408755] Step 1665/1692: training loss=0.00\n",
            "[1747408755] Step 1666/1692: training loss=0.00\n",
            "[1747408758] Step 1667/1692: training loss=0.98\n",
            "[1747408758] Step 1668/1692: training loss=0.71\n",
            "[1747408761] Step 1669/1692: training loss=0.00\n",
            "[1747408761] Step 1670/1692: training loss=0.00\n",
            "[1747408763] Step 1671/1692: training loss=0.96\n",
            "📌 Estado actual: running\n",
            "[1747408764] Step 1672/1692: training loss=0.84\n",
            "[1747408767] Step 1673/1692: training loss=0.35\n",
            "[1747408767] Step 1674/1692: training loss=0.00\n",
            "[1747408769] Step 1675/1692: training loss=0.00\n",
            "[1747408769] Step 1676/1692: training loss=0.00\n",
            "[1747408772] Step 1677/1692: training loss=0.00\n",
            "[1747408775] Step 1678/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408775] Step 1679/1692: training loss=0.00\n",
            "[1747408778] Step 1680/1692: training loss=0.00\n",
            "[1747408778] Step 1681/1692: training loss=0.00\n",
            "[1747408780] Step 1682/1692: training loss=0.00\n",
            "[1747408781] Step 1683/1692: training loss=0.00\n",
            "[1747408783] Step 1684/1692: training loss=0.72\n",
            "[1747408783] Step 1685/1692: training loss=0.00\n",
            "[1747408786] Step 1686/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "[1747408786] Step 1687/1692: training loss=0.00\n",
            "[1747408789] Step 1688/1692: training loss=0.00\n",
            "[1747408789] Step 1689/1692: training loss=0.00\n",
            "[1747408791] Step 1690/1692: training loss=0.00\n",
            "📌 Estado actual: running\n",
            "📌 Estado actual: running\n",
            "📌 Estado actual: succeeded\n",
            "[1747408792] Step 1691/1692: training loss=0.00\n",
            "[1747408794] Step 1692/1692: training loss=0.00\n",
            "[1747408822] Checkpoint created at step 564\n",
            "[1747408822] Checkpoint created at step 1128\n",
            "[1747408823] New fine-tuned model created\n",
            "[1747408829] The job has successfully completed\n",
            "\n",
            "✅ Fine-tuning finalizado con estado: succeeded\n"
          ]
        }
      ],
      "source": [
        "fine_tune_id = fine_tune_response.id  # o coloca directamente el ID del fine-tune job\n",
        "\n",
        "seen_event_ids = set()\n",
        "\n",
        "print(f\"⏳ Monitoreando el fine-tuning con ID: {fine_tune_id}\\n\")\n",
        "\n",
        "while True:\n",
        "    # Obtener el estado actual del trabajo\n",
        "    status = openai.fine_tuning.jobs.retrieve(fine_tune_id)\n",
        "    print(f\"📌 Estado actual: {status.status}\")\n",
        "\n",
        "    # Obtener nuevos eventos\n",
        "    events = openai.fine_tuning.jobs.list_events(fine_tuning_job_id=fine_tune_id).data\n",
        "    events.reverse()  # Para mostrar los eventos en orden cronológico\n",
        "\n",
        "    for event in events:\n",
        "        if event.id not in seen_event_ids:\n",
        "            print(f\"[{event.created_at}] {event.message}\")\n",
        "            seen_event_ids.add(event.id)\n",
        "\n",
        "    # Terminar si el fine-tuning finalizó\n",
        "    if status.status in [\"succeeded\", \"failed\", \"cancelled\"]:\n",
        "        print(f\"\\n✅ Fine-tuning finalizado con estado: {status.status}\")\n",
        "        break\n",
        "\n",
        "    # Esperar antes de volver a consultar\n",
        "    time.sleep(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6msIokxi7Rq4",
        "outputId": "a31bd748-4078-4473-84d6-bb91d860fc54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID: ftjob-JBXGZMskmrvK7dvrnPkRzPYr\n",
            "Estado: succeeded\n",
            "Modelo resultado: ft:gpt-3.5-turbo-0125:personal::BXr9Cyox\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "jobs = openai.fine_tuning.jobs.list(limit=10)\n",
        "\n",
        "for job in jobs.data:\n",
        "    print(f\"ID: {job.id}\")\n",
        "    print(f\"Estado: {job.status}\")\n",
        "    print(f\"Modelo resultado: {job.fine_tuned_model}\")\n",
        "    print(\"----------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4azDPZGxfoR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "# Store model ID\n",
        "model_id = \"ft:gpt-4.1-mini-2025-04-14:spicichondaturo-organization:rad-alert:BTHGm3D8\"\n",
        "\n",
        "# Function to get model prediction for a single text\n",
        "def get_prediction(text):\n",
        "    try:\n",
        "        response = client.responses.create(\n",
        "            model=model_id,\n",
        "            input=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"input_text\",\n",
        "                            \"text\": (\n",
        "                                \"Eres un especialista en radiologia, y tienes que analizar el siguiente informe radiológico escrito en español y determinar si contiene hallazgos clínicos **críticos** que requieren atención médica urgente. \"\n",
        "                                \"No inventes ni asumas información adicional; basa tu decisión solo en el contenido del texto. \"\n",
        "                                \"Responde estrictamente con un solo número: **1** si el informe es crítico, o **0** si no lo es. No añadas explicaciones ni comentarios.\"\n",
        "                            )\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"input_text\",\n",
        "                            \"text\": text\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "            text={\"format\": {\"type\": \"text\"}},\n",
        "            reasoning={},\n",
        "            tools=[],\n",
        "            temperature=0,  # Deterministic\n",
        "            max_output_tokens=20,\n",
        "            top_p=1,\n",
        "            store=False\n",
        "        )\n",
        "\n",
        "        prediction = int(response.output[0].content[0].text)\n",
        "        return prediction\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error with input: {text[:50]}... | Error: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6ete4dU6OEz",
        "outputId": "fe942a7b-189a-4e74-b48b-b2e88c79928c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_prediction(df_test['texto'].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPHYKp0c5sC0"
      },
      "outputs": [],
      "source": [
        "# Apply model to test dataframe\n",
        "df_test['predicted'] = df_test['texto'].apply(lambda x: get_prediction(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJAOC-LXeEsO"
      },
      "source": [
        "No prestar atencion a esto\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0hAsPAtCbV6",
        "outputId": "9bb4d7f0-a1b3-41b8-81c1-0724131d10a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9315    0.9907    0.9601       535\n",
            "           1     0.9444    0.6855    0.7944       124\n",
            "\n",
            "    accuracy                         0.9332       659\n",
            "   macro avg     0.9380    0.8381    0.8773       659\n",
            "weighted avg     0.9339    0.9332    0.9290       659\n",
            "\n",
            "Confusion Matrix:\n",
            "[[530   5]\n",
            " [ 39  85]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Optional: wait between calls to avoid rate limits\n",
        "# time.sleep(1)\n",
        "\n",
        "# Drop rows where prediction failed\n",
        "df_test = df_test.dropna(subset=['predicted'])\n",
        "\n",
        "# Calculate metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(df_test['etiqueta'], df_test['predicted'], digits=4))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(df_test['etiqueta'], df_test['predicted']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Ui3cnODaCeW3",
        "outputId": "892ef599-a821-4d43-ad7d-3bbb0b9a74c8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(df_test['etiqueta'], df_test['predicted'])\n",
        "\n",
        "# Optional: define class labels (adjust to your problem)\n",
        "labels = ['No Crítico', 'Crítico']  # 0 = No crítico, 1 = Crítico\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqXg9wDnCfFP"
      },
      "source": [
        "---\n",
        "Ignore this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4DQR7paf4jo"
      },
      "outputs": [],
      "source": [
        "concatenated_string_json = \"\"\n",
        "\n",
        "for index, row in df_test.iterrows():\n",
        "    # Limpia el texto\n",
        "    clean_text = str(row[\"texto\"]).replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace('\"', '\\\\\"')\n",
        "    label = str(row[\"label\"]).replace('\"', '\\\\\"')\n",
        "\n",
        "    concatenated_string_json += (\n",
        "        f'{{'\n",
        "        f'\"messages\": ['\n",
        "        f'{{ \"role\": \"system\", \"content\": \" '\n",
        "        f'Eres un especialista en radiologia, y tienes que analizar el siguiente informe radiológico escrito en español y determinar si contiene hallazgos clínicos **críticos** que requieren atención médica urgente. '\n",
        "        f'Un informe se considera crítico si describe condiciones potencialmente mortales, cambios agudos severos, o hallazgos que requieren una intervención inmediata. '\n",
        "        f'No inventes ni asumas información adicional; basa tu decisión solo en el contenido del texto. '\n",
        "        f'Responde estrictamente con un solo número: **1** si el informe es crítico, o **0** si no lo es. No añadas explicaciones ni comentarios.\" }} , '\n",
        "        f'{{ \"role\": \"user\", \"content\": \"{clean_text}\" }}, '\n",
        "        f'{{ \"role\": \"assistant\", \"content\": \"{label}\" }}'\n",
        "        f']'\n",
        "        f'}} \\n'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kUwY_yugFgO"
      },
      "outputs": [],
      "source": [
        "with open('concatenated_string_json_test.jsonl', 'w') as f:\n",
        "  f.write(concatenated_string_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muBGdTcjsBds",
        "outputId": "db223cbd-4fb5-43bd-b2e3-c2c4874e7521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CEFALEA + ÉMESIS. La atenuación del parénquima es normal y no se observan masas ni desviación de las estructuras de la línea media.\n",
            "El sistema ventricular no muestra alteraciones.\n",
            "No hay evidencia de hemorragia intracraneana, infarto agudo, ni colecciones extra-axiales.\n",
            "No se observan líneas de fractura.\n",
            "Las porciones visualizadas de las orbitas y mastoides no muestran alteraciones. Engrosamiento mucoso en ambos senos maxilares, con presencia a nivel hidroaéreo en el seno maxilar derecho.\n",
            "En la porción visualizada del cuello llama la atención heterogeneidad de la densidad de ambas glándulas parótidas, con microcalcificaciones, a correlacionar con antecedentes. Estudio sin evidencia de procesos patológicos agudos intracraneales.\n",
            "\n",
            "Sinusopatía aguda maxilar derecha.\n"
          ]
        }
      ],
      "source": [
        "#show the first register of df_test show all the text\n",
        "for index, row in df_test.iterrows():\n",
        "    # Limpia el texto\n",
        "    print(row[\"texto\"])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1fr0jrddX9P"
      },
      "source": [
        "## **Data preparation and analysis for chat model fine-tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g1nW3aNdce3",
        "outputId": "9ff4bfce-dd03-45ea-8e47-da3de2b7f2cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TieATa3WdWOb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En9hjoEMdjPk",
        "outputId": "892e727c-be2e-431c-9ffc-817136940eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples: 2701\n",
            "First example:\n",
            "{'role': 'system', 'content': ' Eres un especialista en radiologia, y tienes que analizar el siguiente informe radiológico escrito en español y determinar si contiene hallazgos clínicos **críticos** que requieren atención médica urgente. Un informe se considera crítico si describe condiciones potencialmente mortales, cambios agudos severos, o hallazgos que requieren una intervención inmediata. No inventes ni asumas información adicional; basa tu decisión solo en el contenido del texto. Responde estrictamente con un solo número: **1** si el informe es crítico, o **0** si no lo es. No añadas explicaciones ni comentarios.'}\n",
            "{'role': 'user', 'content': 'EPISODIO CONVULSIVO. Llama la atención hiperdensidad del tentorio del cerebelo en el lado derecho sin identificar una clara imagen de hematoma o hemorragia.  Surcos y circunvoluciones simétricos.  Sistema ventricular de tamaño, configuración y densidad normales.  Línea media central.  Adecuada diferenciación de la sustancia blanca y gris, sin que se aprecien lesiones de tipo desmielinizante.  No colecciones epi o subdurales, signos de hemorragia subaracnoidea o parenquimatosa.  IV ventrículo central.  Megacisterna magna como variante de la anatomía.  Con las ventanas óseas no evidencia de fracturas.  Porción visible de órbitas de aspecto normal.  Adecuada neumatización de mastoides y senos paranasales para la edad. Hiperdensidad del tentorio del cerebelo en el lado derecho sin una clara imagen de hematoma / hemorragia,PUEDE SER UN HALLAZGO USUSAL EN EL RANGO DE EDAD. Se recomienda seguimiento.'}\n",
            "{'role': 'assistant', 'content': '0'}\n"
          ]
        }
      ],
      "source": [
        "data_path = \"concatenated_string_json.jsonl\"\n",
        "\n",
        "# Load the dataset\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boZbPlSwdyKF",
        "outputId": "67653a4b-e1ef-48ad-dc81-183bc0688d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No errors found\n"
          ]
        }
      ],
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        function_call = message.get(\"function_call\", None)\n",
        "\n",
        "        if (not content and not function_call) or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuouQNk8d0WP"
      },
      "outputs": [],
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI7kEe0yd4ej",
        "outputId": "4e6d7168-c178-4eb3-f025-d083ca6ebab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 198, 1019\n",
            "mean / median: 441.34727878563496, 431.0\n",
            "p5 / p95: 303.0, 574.0\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 1, 1\n",
            "mean / median: 1.0, 1.0\n",
            "p5 / p95: 1.0, 1.0\n",
            "\n",
            "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n"
          ]
        }
      ],
      "source": [
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 16385 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 16,385 token limit, they will be truncated during fine-tuning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7Bk_z-sd8ZC"
      },
      "source": [
        "## **Cost Estimation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKUoWm3fd70L",
        "outputId": "3dc362fd-6701-4d0c-9afd-025c283a7cd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset has ~1192079 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~3576237 tokens\n"
          ]
        }
      ],
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 16385\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9qZdsnNteYR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "# Store model ID\n",
        "model_id = \"ft:gpt-4.1-mini-2025-04-14:spicichondaturo-organization:rad-alert:BTHGm3D8\"\n",
        "\n",
        "# Function to get model prediction for a single text\n",
        "def get_prediction(text):\n",
        "    try:\n",
        "        response = client.responses.create(\n",
        "            model=model_id,\n",
        "            input=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"input_text\",\n",
        "                            \"text\": (\n",
        "                                \"Eres un especialista en radiologia, y tienes que analizar el siguiente informe radiológico escrito en español y determinar si contiene hallazgos clínicos **críticos** que requieren atención médica urgente. \"\n",
        "                                \"No inventes ni asumas información adicional; basa tu decisión solo en el contenido del texto. \"\n",
        "                                \"Responde estrictamente con un solo número: **1** si el informe es crítico, o **0** si no lo es. No añadas explicaciones ni comentarios.\"\n",
        "                            )\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"input_text\",\n",
        "                            \"text\": text\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "            text={\"format\": {\"type\": \"text\"}},\n",
        "            reasoning={},\n",
        "            tools=[],\n",
        "            temperature=0,  # Deterministic\n",
        "            max_output_tokens=20,\n",
        "            top_p=1,\n",
        "            store=False\n",
        "        )\n",
        "\n",
        "        prediction = int(response.output[0].content[0].text)\n",
        "        return prediction\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error with input: {text[:50]}... | Error: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv0QUyifZ9ye"
      },
      "source": [
        "## **6. Evaluación de desempeño**\n",
        "\n",
        "* Se eliminan filas con predicciones nulas (por ejemplo, debido a errores en la API).\n",
        "* Se calcula un **reporte de clasificación** (accuracy, precision, recall, F1-score) usando `sklearn`.\n",
        "* Se genera la **matriz de confusión** y se visualiza con un mapa de calor (seaborn + matplotlib), permitiendo analizar visualmente los aciertos y errores del modelo (por ejemplo, falsos negativos o positivos)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W526PZgtt1d",
        "outputId": "7a59d912-f1b9-4cbc-a961-ecb04ac0bfb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9775    0.9838    0.9806       618\n",
            "           1     0.8148    0.7586    0.7857        58\n",
            "\n",
            "    accuracy                         0.9645       676\n",
            "   macro avg     0.8962    0.8712    0.8832       676\n",
            "weighted avg     0.9635    0.9645    0.9639       676\n",
            "\n",
            "Confusion Matrix:\n",
            "[[608  10]\n",
            " [ 14  44]]\n"
          ]
        }
      ],
      "source": [
        "# Apply model to test dataframe\n",
        "df_test['predicted'] = df_test['texto'].apply(lambda x: get_prediction(x))\n",
        "\n",
        "# Optional: wait between calls to avoid rate limits\n",
        "# time.sleep(1)\n",
        "\n",
        "# Drop rows where prediction failed\n",
        "df_test = df_test.dropna(subset=['predicted'])\n",
        "\n",
        "# Calculate metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(df_test['etiqueta'], df_test['predicted'], digits=4))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(df_test['etiqueta'], df_test['predicted']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO31pUv0zMlu",
        "outputId": "8eb3604f-9eb9-4e66-8392-0766051bebad"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAHWCAYAAADuNVprAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASdFJREFUeJzt3XlcVNX/P/DXDMswoqwKiAtibqCouCRIuaJouKVlJinuZpAprvR1QS1RzD2X9GNCbqWmllYqomIqLpEoKuIeHxNwBRTZhPv7w5/zcQR00BmucF7Pz+M+HnLumXPfMx+IN+9zzr0KSZIkEBERkXCUcgdARERE8mASQEREJCgmAURERIJiEkBERCQoJgFERESCYhJAREQkKCYBREREgmISQEREJCgmAURERIJiEkCko0uXLqFz586wtLSEQqHAjh079Dr+9evXoVAoEB4ertdxy7J27dqhXbt2codBVG4xCaAy5cqVKxg5ciRq164NMzMzWFhYwMvLC4sXL0ZWVpZBr+3v74/4+Hh8/fXXWLduHVq0aGHQ65WmQYMGQaFQwMLCosjP8dKlS1AoFFAoFPjmm29KPP7NmzcREhKCuLg4PURLRPpiLHcARLr67bff8OGHH0KlUmHgwIFo1KgRcnNzcfjwYUyYMAHnzp3DqlWrDHLtrKwsxMTE4P/+7/8QGBhokGs4OTkhKysLJiYmBhn/ZYyNjfHo0SPs3LkTffv21Tq3YcMGmJmZITs7+5XGvnnzJmbMmIFatWqhadOmOr9u7969r3Q9ItINkwAqE65du4Z+/frByckJ+/fvR9WqVTXnAgICcPnyZfz2228Gu/7t27cBAFZWVga7hkKhgJmZmcHGfxmVSgUvLy9s2rSpUBKwceNG+Pr64ueffy6VWB49eoQKFSrA1NS0VK5HJCpOB1CZEBYWhocPH2LNmjVaCcBTderUwRdffKH5+vHjx5g1axbeeustqFQq1KpVC19++SVycnK0XlerVi1069YNhw8fxttvvw0zMzPUrl0bP/zwg6ZPSEgInJycAAATJkyAQqFArVq1ADwpoz/997NCQkKgUCi02iIjI/HOO+/AysoKFStWRP369fHll19qzhe3JmD//v149913YW5uDisrK/Ts2RMJCQlFXu/y5csYNGgQrKysYGlpicGDB+PRo0fFf7DP6d+/P/744w+kpaVp2k6ePIlLly6hf//+hfrfu3cP48ePh5ubGypWrAgLCwt07doVp0+f1vQ5ePAgWrZsCQAYPHiwZlrh6fts164dGjVqhNjYWLRp0wYVKlTQfC7Prwnw9/eHmZlZoffv4+MDa2tr3Lx5U+f3SkRMAqiM2LlzJ2rXro3WrVvr1H/YsGGYNm0amjVrhoULF6Jt27YIDQ1Fv379CvW9fPkyPvjgA3Tq1Anz58+HtbU1Bg0ahHPnzgEAevfujYULFwIAPv74Y6xbtw6LFi0qUfznzp1Dt27dkJOTg5kzZ2L+/Pno0aMHjhw58sLX7du3Dz4+Prh16xZCQkIQFBSEo0ePwsvLC9evXy/Uv2/fvnjw4AFCQ0PRt29fhIeHY8aMGTrH2bt3bygUCmzbtk3TtnHjRjRo0ADNmjUr1P/q1avYsWMHunXrhgULFmDChAmIj49H27ZtNb+QXVxcMHPmTADAiBEjsG7dOqxbtw5t2rTRjHP37l107doVTZs2xaJFi9C+ffsi41u8eDGqVKkCf39/5OfnAwC+++477N27F0uXLoWjo6PO75WIAEhEb7j09HQJgNSzZ0+d+sfFxUkApGHDhmm1jx8/XgIg7d+/X9Pm5OQkAZAOHTqkabt165akUqmkcePGadquXbsmAZDmzZunNaa/v7/k5ORUKIbp06dLz/54LVy4UAIg3b59u9i4n15j7dq1mramTZtKdnZ20t27dzVtp0+flpRKpTRw4MBC1xsyZIjWmO+//75ka2tb7DWffR/m5uaSJEnSBx98IHXs2FGSJEnKz8+XHBwcpBkzZhT5GWRnZ0v5+fmF3odKpZJmzpypaTt58mSh9/ZU27ZtJQDSypUrizzXtm1brbY9e/ZIAKSvvvpKunr1qlSxYkWpV69eL32PRFQYKwH0xsvIyAAAVKpUSaf+v//+OwAgKChIq33cuHEAUGjtgKurK959913N11WqVEH9+vVx9erVV475eU/XEvzyyy8oKCjQ6TXJycmIi4vDoEGDYGNjo2lv3LgxOnXqpHmfz/r000+1vn733Xdx9+5dzWeoi/79++PgwYNISUnB/v37kZKSUuRUAPBkHYFS+eQ/I/n5+bh7965mquPvv//W+ZoqlQqDBw/WqW/nzp0xcuRIzJw5E71794aZmRm+++47na9FRP/DJIDeeBYWFgCABw8e6NT/n3/+gVKpRJ06dbTaHRwcYGVlhX/++UervWbNmoXGsLa2xv37918x4sI++ugjeHl5YdiwYbC3t0e/fv2wefPmFyYET+OsX79+oXMuLi64c+cOMjMztdqffy/W1tYAUKL38t5776FSpUr46aefsGHDBrRs2bLQZ/lUQUEBFi5ciLp160KlUqFy5cqoUqUKzpw5g/T0dJ2vWa1atRItAvzmm29gY2ODuLg4LFmyBHZ2djq/loj+h0kAvfEsLCzg6OiIs2fPluh1zy/MK46RkVGR7ZIkvfI1ns5XP6VWq3Ho0CHs27cPAwYMwJkzZ/DRRx+hU6dOhfq+jtd5L0+pVCr07t0bERER2L59e7FVAACYPXs2goKC0KZNG6xfvx579uxBZGQkGjZsqHPFA3jy+ZTEqVOncOvWLQBAfHx8iV5LRP/DJIDKhG7duuHKlSuIiYl5aV8nJycUFBTg0qVLWu2pqalIS0vTrPTXB2tra62V9E89X20AAKVSiY4dO2LBggU4f/48vv76a+zfvx8HDhwocuyncSYmJhY6d+HCBVSuXBnm5uav9waK0b9/f5w6dQoPHjwocjHlU1u3bkX79u2xZs0a9OvXD507d4a3t3ehz0TXhEwXmZmZGDx4MFxdXTFixAiEhYXh5MmTehufSCRMAqhMmDhxIszNzTFs2DCkpqYWOn/lyhUsXrwYwJNyNoBCK/gXLFgAAPD19dVbXG+99RbS09Nx5swZTVtycjK2b9+u1e/evXuFXvv0pjnPb1t8qmrVqmjatCkiIiK0fqmePXsWe/fu1bxPQ2jfvj1mzZqFb7/9Fg4ODsX2MzIyKlRl2LJlC/7991+ttqfJSlEJU0lNmjQJSUlJiIiIwIIFC1CrVi34+/sX+zkSUfF4syAqE9566y1s3LgRH330EVxcXLTuGHj06FFs2bIFgwYNAgA0adIE/v7+WLVqFdLS0tC2bVucOHECERER6NWrV7Hbz15Fv379MGnSJLz//vsYPXo0Hj16hBUrVqBevXpaC+NmzpyJQ4cOwdfXF05OTrh16xaWL1+O6tWr45133il2/Hnz5qFr167w9PTE0KFDkZWVhaVLl8LS0hIhISF6ex/PUyqVmDJlykv7devWDTNnzsTgwYPRunVrxMfHY8OGDahdu7ZWv7feegtWVlZYuXIlKlWqBHNzc7Rq1QrOzs4limv//v1Yvnw5pk+frtmyuHbtWrRr1w5Tp05FWFhYicYjEp7MuxOISuTixYvS8OHDpVq1akmmpqZSpUqVJC8vL2np0qVSdna2pl9eXp40Y8YMydnZWTIxMZFq1KghBQcHa/WRpCdbBH19fQtd5/mtacVtEZQkSdq7d6/UqFEjydTUVKpfv760fv36QlsEo6KipJ49e0qOjo6Sqamp5OjoKH388cfSxYsXC13j+W10+/btk7y8vCS1Wi1ZWFhI3bt3l86fP6/V5+n1nt+CuHbtWgmAdO3atWI/U0nS3iJYnOK2CI4bN06qWrWqpFarJS8vLykmJqbIrX2//PKL5OrqKhkbG2u9z7Zt20oNGzYs8prPjpORkSE5OTlJzZo1k/Ly8rT6jR07VlIqlVJMTMwL3wMRaVNIUglWDBEREVG5wTUBREREgmISQEREJCgmAURERIJiEkBERCQoJgFERESCYhJAREQkKCYBREREgiqXdwxUuwfKHQKRwd0/+a3cIRAZnJmBf0vp8/dF1qmy9zPJSgAREYlLodTfUUL//vsvPvnkE9ja2kKtVsPNzQ1//fWX5rwkSZg2bRqqVq0KtVoNb2/vQg9Gu3fvHvz8/GBhYQErKysMHToUDx8+1DkGJgFERESl7P79+/Dy8oKJiQn++OMPnD9/HvPnz4e1tbWmT1hYGJYsWYKVK1fi+PHjMDc3h4+PD7KzszV9/Pz8cO7cOURGRmLXrl04dOgQRowYoXMc5fK2wZwOIBFwOoBEYPDpgOZf6G2srNjFOvedPHkyjhw5gj///LPI85IkwdHREePGjcP48eMBAOnp6bC3t0d4eDj69euHhIQEuLq64uTJk2jRogUAYPfu3Xjvvfdw48YNODo6vjQOVgKIiEhcepwOyMnJQUZGhtZR3COuf/31V7Ro0QIffvgh7Ozs4O7ujtWrV2vOX7t2DSkpKfD29ta0WVpaolWrVoiJiQEAxMTEwMrKSpMAAIC3tzeUSiWOHz+u09tnEkBERKQHoaGhsLS01DpCQ0OL7Hv16lWsWLECdevWxZ49ezBq1CiMHj0aERERAICUlBQAgL29vdbr7O3tNedSUlJgZ2endd7Y2Bg2NjaaPi9TLncHEBER6USh0NtQwcHBCAoK0mpTqVRF9i0oKECLFi0we/ZsAIC7uzvOnj2LlStXwt/fX28xvQwrAUREJC49TgeoVCpYWFhoHcUlAVWrVoWrq6tWm4uLC5KSkgAADg4OAIDU1FStPqmpqZpzDg4OuHXrltb5x48f4969e5o+L8MkgIiIqJR5eXkhMTFRq+3ixYtwcnICADg7O8PBwQFRUVGa8xkZGTh+/Dg8PT0BAJ6enkhLS0NsbKymz/79+1FQUIBWrVrpFAenA4iISFx6nA4oibFjx6J169aYPXs2+vbtixMnTmDVqlVYtWrV/w9LgTFjxuCrr75C3bp14ezsjKlTp8LR0RG9evUC8KRy0KVLFwwfPhwrV65EXl4eAgMD0a9fP512BgBMAoiISGSvcJMffWjZsiW2b9+O4OBgzJw5E87Ozli0aBH8/Pw0fSZOnIjMzEyMGDECaWlpeOedd7B7926YmZlp+mzYsAGBgYHo2LEjlEol+vTpgyVLlugcB+8TQFRG8T4BJAKD3yfAY5Lexso6NldvY5UWVgKIiEhcMk0HvCmYBBARkbhkmg54U4j97omIiATGSgAREYmL0wFERESC4nQAERERiYiVACIiEhenA4iIiATF6QAiIiISESsBREQkLsErAUwCiIhIXEqx1wSInQIREREJjJUAIiISF6cDiIiIBCX4FkGxUyAiIiKBsRJARETi4nQAERGRoDgdQERERCJiJYCIiMTF6QAiIiJBcTqAiIiIRMRKABERiYvTAURERILidAARERGJiJUAIiISF6cDiIiIBMXpACIiIhIRKwFERCQuTgcQEREJSvAkQOx3T0REJDBWAoiISFyCLwxkEkBEROLidAARERGJiJUAIiISF6cDiIiIBMXpACIiIhIRKwFERCQuTgcQERGJSSF4EsDpACIiIkGxEkBERMISvRLAJICIiMQldg7A6QAiIiJRsRJARETC4nQAERGRoERPAjgdQEREJChWAoiISFiiVwKYBBARkbBETwI4HUBERCQoVgKIiEhcYhcCmAQQEZG4OB1AREREQmIlgIiIhCV6JeCNSQJu376NxMREAED9+vVRpUoVmSMiIqLyTvQkQPbpgMzMTAwZMgSOjo5o06YN2rRpA0dHRwwdOhSPHj2SOzwiIiK9CwkJgUKh0DoaNGigOZ+dnY2AgADY2tqiYsWK6NOnD1JTU7XGSEpKgq+vLypUqAA7OztMmDABjx8/LlEcsicBQUFBiI6Oxq+//oq0tDSkpaXhl19+QXR0NMaNGyd3eEREVI49/4v4dY6SatiwIZKTkzXH4cOHNefGjh2LnTt3YsuWLYiOjsbNmzfRu3dvzfn8/Hz4+voiNzcXR48eRUREBMLDwzFt2rQSxSD7dMDPP/+MrVu3ol27dpq29957D2q1Gn379sWKFSvkC46IiMo3GWcDjI2N4eDgUKg9PT0da9aswcaNG9GhQwcAwNq1a+Hi4oJjx47Bw8MDe/fuxfnz57Fv3z7Y29ujadOmmDVrFiZNmoSQkBCYmprqFIPslYBHjx7B3t6+ULudnR2nA4iIqMzIyclBRkaG1pGTk1Ns/0uXLsHR0RG1a9eGn58fkpKSAACxsbHIy8uDt7e3pm+DBg1Qs2ZNxMTEAABiYmLg5uam9fvTx8cHGRkZOHfunM4xy54EeHp6Yvr06cjOzta0ZWVlYcaMGfD09JQxMiIiKu/0OR0QGhoKS0tLrSM0NLTI67Zq1Qrh4eHYvXs3VqxYgWvXruHdd9/FgwcPkJKSAlNTU1hZWWm9xt7eHikpKQCAlJSUQn9AP/36aR9dyD4dsHjxYvj4+KB69epo0qQJAOD06dMwMzPDnj17ZI6OiIjKM33uDggODkZQUJBWm0qlKrJv165dNf9u3LgxWrVqBScnJ2zevBlqtVpvMb2M7ElAo0aNcOnSJWzYsAEXLlwAAHz88cfw8/Mr1Q+CiIjodahUqmJ/6b+MlZUV6tWrh8uXL6NTp07Izc1FWlqaVjUgNTVVs4bAwcEBJ06c0Brj6e6BotYZFEf2JAAAKlSogOHDh8sdBhERCeZNuU/Aw4cPceXKFQwYMADNmzeHiYkJoqKi0KdPHwBAYmIikpKSNNPknp6e+Prrr3Hr1i3Y2dkBACIjI2FhYQFXV1edryv7moDQ0FB8//33hdq///57zJ07V4aIiIhIGAo9HiUwfvx4REdH4/r16zh69Cjef/99GBkZ4eOPP4alpSWGDh2KoKAgHDhwALGxsRg8eDA8PT3h4eEBAOjcuTNcXV0xYMAAnD59Gnv27MGUKVMQEBBQomqE7EnAd999p3WDhKcaNmyIlStXyhARERGRYd24cQMff/wx6tevj759+8LW1hbHjh3T3C134cKF6NatG/r06YM2bdrAwcEB27Zt07zeyMgIu3btgpGRETw9PfHJJ59g4MCBmDlzZoniUEiSJOn1nZWQmZkZEhIS4OzsrNV+9epVuLq6au0a0JXaPVBf4RG9se6f/FbuEIgMzszAk9b2w7bobazU/3yot7FKi+yVgBo1auDIkSOF2o8cOQJHR0cZIiIiIlHIecfAN4HsCwOHDx+OMWPGIC8vT3NnpKioKEycOJG3DSYiIjIg2ZOACRMm4O7du/jss8+Qm5sL4MkUwaRJkxAcHCxzdEREVJ6V1b/g9UX2JEChUGDu3LmYOnUqEhISoFarUbdu3Vfea0lERKQrJgFviIoVK6Jly5Zyh0FERCQMWZKA3r17Izw8HBYWFlqPRizKs1siiIiI9ErsQoA8SYClpaWmBGNhYSF8OYaIiOQh+u8fWZKAtWvXav4dHh4uRwhERETCk/0+AR06dEBaWlqh9oyMDM2WQSIiIkPgfQJkdvDgQc3WwGdlZ2fjzz//lCEiIiISRVn95a0vsiUBZ86c0fz7/PnzSElJ0Xydn5+P3bt3o1q1anKERkREJATZkoCmTZtqSihFlf3VajWWLl0qQ2RERCQMsQsB8iUB165dgyRJqF27Nk6cOKF5chIAmJqaws7ODkZGRnKFR0REAuB0QCmLiIiAh4cH6tevDwAoKCgo7RCIiIgIMiQBVatWRefOnfHTTz/Bw8MDv/766wv79+jRo5QiIyIi0bASUMo6d+6MX3/9FQMGDMCZM2fQq1evYvsqFArk5+eXXnCkxbGKJb76oic6ezVEBTMTXPnvHYwMWY+/zydp+kwd5YvB77eGVSU1Yk5fxejZP+FK0m3N+To17TB7bC94NqkNUxMjnL10EzOW78Khvy7J8ZaIXir2r5MI/34NEs6fxe3bt7FwyTJ06OitOS9JEpZ/uwTbtm7BgwcZaOreDP83LQROTrXkC5pemehJgCz3CWjSpAkOHToE4Ml0QHEHEwD5WFVSY394EPIeF6BX4HK49/kakxdsw/2MR5o+4wZ547OP22L07B/RZuA3yMzKxc5lAVCZ/i+33LbkUxgbKdF15BK09gvDmYv/YtuST2FvW0mOt0X0UllZj1C/fn0ET5le5Pm1a1Zj04Z1mDI9BOs3bYZarcaoEUORk5NTypESvT7ZbhZkZWWFvLw8dOzYEZcu8a/CN824wZ1wI+U+Roasx1/n/sE/N+8i6tgFXLtxR9MnoH97zF29B7sOxuPspZsYNvUHVK1iiR7tmwAAbK3MUdfJDvPXRuLspZu4knQbU5f8AnO1Cq51HOV6a0Qv9M67bRH4xVh09O5U6JwkSdiw7gcMHzkK7Tt4o179BvgqNAy3b93C/qh9MkRLr0v0mwXJesdAExMTrfsF0JvDt60b/j6fhA1hQ/BPVChiNk3C4Pdba87XqmaLqlUssf/4BU1bxsNsnDx7Ha0a1wIA3E3LROK1FPTv9jYqmJnCyEiJYX3eQerdDJx6ZkqBqKz498YN3LlzG608/vezUKlSJbg1boIzp0/JGBm9MoUejzJI9tsGf/LJJ1izZs0rvz4nJwcZGRlah1TAaYTX5VytMoZ/+C4uJ91Gj8+WYfWWw5g/8QP4dW8FAHCobAEAuHXvgdbrbt19AHtbC83Xvp9+iyYNauD2kW+QdmwhRg/ogJ4By5H2IKv03gyRnty582S9i21lW612W1tb3Llzp6iXEL3RZL9t8OPHj/H9999j3759aN68OczNzbXOL1iw4IWvDw0NxYwZM7TajOxbwqTq23qPVSRKpQJ/n0/C9G93AgBOJ95AwzpVMfyDd7Bh53Gdx1kY3Be37z2A95BFyMrJxaD3W+PnxSPxzifzkHInw1DhExHppKyW8fVF9krA2bNn0axZM1SqVAkXL17EqVOnNEdcXNxLXx8cHIz09HStw9i+ueEDL+dS7mQg4WqKVtuFaymo4WCtOQ8AdjbaC/zsbCsh9e6Tc+3erof33m2EgZPXIub0VcRduIExoZuRlZOHT/5/RYGoLKlc+clNze7euavVfvfuXVSuXFmOkOg1ib4mQPZKwIEDB17r9SqVCiqVSqtNoeSdBl9XTNxV1HOy02qrW9MOScn3AADX/72L5NvpaN+qPs5c/BcAUMncDC0b1cLqLYcBABXMTAEUviFUQYFUZn9gSGzVqldH5cpVcPx4DBq4uAAAHj58iPgzp/HhRx/LHB1RyclWCcjPz8eZM2eQlVV4bjgrKwtnzpzh3QRltHT9frzt5owJQzqjdo3K+KhLCwzp44Xvfjqk6bNs4wFMGtYFvm3d0LCOI9bMGoDk2+n49cBpAMDxM9dwP+MR/jNrINzqVXtyz4AxvVCrmi12Hz4n11sjeqFHmZm4kJCACwkJAJ4sBryQkIDkmzehUCjgN2AgVn+3Agf3R+HSxURMCZ6IKnZ2WvcSoLJDodDfURYpJEmS5LhweHg4vv32Wxw/frzQMwIeP34MDw8PjBkzBp988kmJx1a7B+orTKF1fbcRZn7eA3VqVsH1f+9iyfr9WLv9qFafqaN8MaS3F6wqqXE07gq+mL0Zl5Nuac43c62JkIDuaOZaEybGSiRcTcHsVX9g75Hzpf12yp37J7+VO4Ry6eSJ4xg2eGCh9h4938es2XM0Nwv6ectmPHiQAfdmzfHl1OmoVctZhmjLPzMD16vrTtitt7Euzeuit7FKi2xJwLvvvouAgAD069evyPObN2/Gt99+q7mpUEkwCSARMAkgETAJMCzZ1gQkJibCw8Oj2PMtW7ZEwv8vxxERERlCWS3j64tsSUBmZiYyMorfIvbgwQM8evSo2PNERESvS/RFyrItDKxbty6OHj1a7PnDhw+jbt26pRgRERGRWGRLAvr3748pU6YUedvg06dPY9q0aejfv78MkRERkShE3x0g23TA2LFj8ccff6B58+bw9vZGgwYNAAAXLlzAvn374OXlhbFjx8oVHhERCUCpLKO/vfVEtiTAxMQEe/fuxcKFC7Fx40YcOnQIkiShXr16+PrrrzFmzBiYmJjIFR4REVG5J+sdA01MTDBx4kRMnDhRzjCIiEhQZbWMry+yPzuAiIiI5CH7swOIiIjkIvoWQSYBREQkLMFzAE4HEBERieqNqgQ8fYyB6OUZIiIqHaL/vnkjKgE//PAD3NzcoFaroVar0bhxY6xbt07usIiIqJxTKBR6O8oi2SsBCxYswNSpUxEYGAgvLy8AT24Z/Omnn+LOnTu8YRAREZGByJ4ELF26FCtWrMDAgf97fnePHj3QsGFDhISEMAkgIiKDKaN/wOuN7ElAcnIyWrduXai9devWSE5OliEiIiISRVkt4+uL7GsC6tSpg82bNxdq/+mnn/gUQSIiIgOSvRIwY8YMfPTRRzh06JBmTcCRI0cQFRVVZHJARESkL4IXAuRPAvr06YPjx49j4cKF2LFjBwDAxcUFJ06cgLu7u7zBERFRuSb6dIDsSQAANG/eHOvXr5c7DCIiIqG8EUkAERGRHAQvBMiXBCiVypeWYRQKBR4/flxKERERkWg4HSCT7du3F3suJiYGS5YsQUFBQSlGREREJBbZkoCePXsWaktMTMTkyZOxc+dO+Pn5YebMmTJERkREohC8ECD/fQIA4ObNmxg+fDjc3Nzw+PFjxMXFISIiAk5OTnKHRkRE5Zjozw6QNQlIT0/HpEmTUKdOHZw7dw5RUVHYuXMnGjVqJGdYREREQpBtOiAsLAxz586Fg4MDNm3aVOT0ABERkSGV0T/g9Ua2JGDy5MlQq9WoU6cOIiIiEBERUWS/bdu2lXJkREQkirJaxtcX2aYDBg4ciL59+8LGxgaWlpbFHkREROXZnDlzoFAoMGbMGE1bdnY2AgICYGtri4oVK6JPnz5ITU3Vel1SUhJ8fX1RoUIF2NnZYcKECSXeVi9bJSA8PFyuSxMREQGQfzrg5MmT+O6779C4cWOt9rFjx+K3337Dli1bYGlpicDAQPTu3RtHjhwBAOTn58PX1xcODg44evQokpOTMXDgQJiYmGD27Nk6X/+N2B1AREQkBzl3Bzx8+BB+fn5YvXo1rK2tNe3p6elYs2YNFixYgA4dOqB58+ZYu3Ytjh49imPHjgEA9u7di/Pnz2P9+vVo2rQpunbtilmzZmHZsmXIzc3VOQYmAURERHqQk5ODjIwMrSMnJ6fY/gEBAfD19YW3t7dWe2xsLPLy8rTaGzRogJo1ayImJgbAk5vqubm5wd7eXtPHx8cHGRkZOHfunM4xMwkgIiJhKRT6O0JDQwutawsNDS3yuj/++CP+/vvvIs+npKTA1NQUVlZWWu329vZISUnR9Hk2AXh6/uk5XfEBQkREJCx97g4IDg5GUFCQVptKpSrU77///S+++OILREZGwszMTG/XfxWsBBAREemBSqWChYWF1lFUEhAbG4tbt26hWbNmMDY2hrGxMaKjo7FkyRIYGxvD3t4eubm5SEtL03pdamoqHBwcAAAODg6Fdgs8/fppH10wCSAiImHJsTCwY8eOiI+PR1xcnOZo0aIF/Pz8NP82MTFBVFSU5jWJiYlISkqCp6cnAMDT0xPx8fG4deuWpk9kZCQsLCzg6uqqcyycDiAiImHJsUWwUqVKhW6Pb25uDltbW0370KFDERQUBBsbG1hYWODzzz+Hp6cnPDw8AACdO3eGq6srBgwYgLCwMKSkpGDKlCkICAgosvpQHCYBREREb5iFCxdCqVSiT58+yMnJgY+PD5YvX645b2RkhF27dmHUqFHw9PSEubk5/P39S/z0XYUkSZK+g5eb2j1Q7hCIDO7+yW/lDoHI4MwM/Kdqu0VH9TbWwTGt9TZWaWElgIiIhCX3HQPlxoWBREREgmIlgIiIhCX6UwSZBBARkbAEzwE4HUBERCQqVgKIiEhYSsFLAUwCiIhIWILnAJwOICIiEhUrAUREJCzuDiAiIhKUUuwcgNMBREREomIlgIiIhMXpACIiIkEJngNwOoCIiEhUrAQQEZGwFBC7FMAkgIiIhMXdAURERCQkVgKIiEhY3B1AREQkKMFzAE4HEBERiYqVACIiEhYfJUxERCQowXMATgcQERGJipUAIiISFncHEBERCUrwHIDTAURERKJiJYCIiITF3QFERESCEjsF4HQAERGRsFgJICIiYXF3ABERkaD4KGEiIiISEisBREQkLE4H6ODXX3/VecAePXq8cjBERESlSfAcQLckoFevXjoNplAokJ+f/zrxEBERUSnRKQkoKCgwdBxERESljtMBREREghJ9d8ArJQGZmZmIjo5GUlIScnNztc6NHj1aL4ERERGRYZU4CTh16hTee+89PHr0CJmZmbCxscGdO3dQoUIF2NnZMQkgIqIyQ/TpgBLfJ2Ds2LHo3r077t+/D7VajWPHjuGff/5B8+bN8c033xgiRiIiIoNQ6PEoi0qcBMTFxWHcuHFQKpUwMjJCTk4OatSogbCwMHz55ZeGiJGIiIgMoMRJgImJCZTKJy+zs7NDUlISAMDS0hL//e9/9RsdERGRASkVCr0dZVGJ1wS4u7vj5MmTqFu3Ltq2bYtp06bhzp07WLduHRo1amSIGImIiAyijP7u1psSVwJmz56NqlWrAgC+/vprWFtbY9SoUbh9+zZWrVql9wCJiIjIMEpcCWjRooXm33Z2dti9e7deAyIiIiotou8O4M2CiIhIWILnACVPApydnV+YOV29evW1AiIiIqLSUeIkYMyYMVpf5+Xl4dSpU9i9ezcmTJigr7iIiIgMrqyu6teXEicBX3zxRZHty5Ytw19//fXaAREREZUWwXOAku8OKE7Xrl3x888/62s4IiIiMjC9LQzcunUrbGxs9DUcERGRwXF3QAm5u7trfWiSJCElJQW3b9/G8uXL9Rrcq7p34lu5QyAyuMycx3KHQGRwZsaG3cSmt3J4GVXiT7dnz55aSYBSqUSVKlXQrl07NGjQQK/BERERkeGUOAkICQkxQBhERESlT67pgBUrVmDFihW4fv06AKBhw4aYNm0aunbtCgDIzs7GuHHj8OOPPyInJwc+Pj5Yvnw57O3tNWMkJSVh1KhROHDgACpWrAh/f3+EhobCuATVkxJXQoyMjHDr1q1C7Xfv3oWRkVFJhyMiIpKNUqG/oySqV6+OOXPmIDY2Fn/99Rc6dOiAnj174ty5cwCAsWPHYufOndiyZQuio6Nx8+ZN9O7dW/P6/Px8+Pr6Ijc3F0ePHkVERATCw8Mxbdq0EsWhkCRJKskLlEolUlJSYGdnp9V+8+ZNvPXWW8jKyipRAIaQlSd3BESG9yiXawKo/LM1N+yagDG/XNDbWIt6vt6UuI2NDebNm4cPPvgAVapUwcaNG/HBBx8AAC5cuAAXFxfExMTAw8MDf/zxB7p164abN29qqgMrV67EpEmTcPv2bZiamup0TZ0/3SVLlgB4Ujr5z3/+g4oVK2rO5efn49ChQ1wTQEREZUpJ/4J/kZycHOTk5Gi1qVQqqFSqF74uPz8fW7ZsQWZmJjw9PREbG4u8vDx4e3tr+jRo0AA1a9bUJAExMTFwc3PTmh7w8fHBqFGjcO7cObi7u+sUs85JwMKFCwE82Q2wcuVKrdK/qakpatWqhZUrV+o6HBERkez0uSYgNDQUM2bM0GqbPn16sWvp4uPj4enpiezsbFSsWBHbt2+Hq6sr4uLiYGpqCisrK63+9vb2SElJAQCkpKRoJQBPzz89pyudk4Br164BANq3b49t27bB2tpa54sQERGVd8HBwQgKCtJqe1EVoH79+oiLi0N6ejq2bt0Kf39/REdHGzpMLSWebDlw4IAh4iAiIip1+pwO0KX0/yxTU1PUqVMHANC8eXOcPHkSixcvxkcffYTc3FykpaVpVQNSU1Ph4OAAAHBwcMCJEye0xktNTdWc01WJdwf06dMHc+fOLdQeFhaGDz/8sKTDERERyUah0N/xugoKCpCTk4PmzZvDxMQEUVFRmnOJiYlISkqCp6cnAMDT0xPx8fFau/UiIyNhYWEBV1dXna9Z4krAoUOHipzf6Nq1K+bPn1/S4YiIiIQTHByMrl27ombNmnjw4AE2btyIgwcPYs+ePbC0tMTQoUMRFBQEGxsbWFhY4PPPP4enpyc8PDwAAJ07d4arqysGDBiAsLAwpKSkYMqUKQgICChRNaLEScDDhw+L3HpgYmKCjIyMkg5HREQkG7keJXzr1i0MHDgQycnJsLS0ROPGjbFnzx506tQJwJPF+EqlEn369NG6WdBTRkZG2LVrF0aNGgVPT0+Ym5vD398fM2fOLFEcJb5PwNtvv41u3boVuiFBSEgIdu7cidjY2BIFYAi8TwCJgPcJIBEY+j4BX/5+UW9jzX6vnt7GKi0l/nSnTp2K3r1748qVK+jQoQMAICoqChs3bsTWrVv1HiAREREZRomTgO7du2PHjh2YPXs2tm7dCrVajSZNmmD//v18lDAREZUpgj9JuORJAAD4+vrC19cXAJCRkYFNmzZh/PjxiI2NRX5+vl4DJCIiMhS51gS8KV75UcqHDh2Cv78/HB0dMX/+fHTo0AHHjh3TZ2xERERkQCWqBKSkpCA8PBxr1qxBRkYG+vbti5ycHOzYsaNE+xKJiIjeBIIXAnSvBHTv3h3169fHmTNnsGjRIty8eRNLly41ZGxEREQGJdejhN8UOlcC/vjjD4wePRqjRo1C3bp1DRkTERERlQKdKwGHDx/GgwcP0Lx5c7Rq1Qrffvst7ty5Y8jYiIiIDEqpUOjtKIt0TgI8PDywevVqJCcnY+TIkfjxxx/h6OiIgoICREZG4sGDB4aMk4iISO/epGcHyKHEuwPMzc0xZMgQHD58GPHx8Rg3bhzmzJkDOzs79OjRwxAxEhERkQG88hZB4MmzkMPCwnDjxg1s2rRJXzERERGVCi4M1AMjIyP06tULvXr10sdwREREpUKBMvrbW09eqxJAREREZZdhH89ERET0BiurZXx9YRJARETCEj0J4HQAERGRoFgJICIiYSnK6gZ/PWESQEREwuJ0ABEREQmJlQAiIhKW4LMBTAKIiEhcZfXBP/rC6QAiIiJBsRJARETCEn1hIJMAIiISluCzAZwOICIiEhUrAUREJCyl4E8RZBJARETC4nQAERERCYmVACIiEhZ3BxAREQmKNwsiIiIiIbESQEREwhK8EMAkgIiIxMXpACIiIhISKwFERCQswQsBTAKIiEhcopfDRX//REREwmIlgIiIhKUQfD6ASQAREQlL7BSA0wFERETCYiWAiIiEJfp9ApgEEBGRsMROATgdQEREJCxWAoiISFiCzwYwCSAiInGJvkWQ0wFERESCYiWAiIiEJfpfwkwCiIhIWJwOICIiIiGxEkBERMISuw7AJICIiATG6QAiIiISEisBREQkLNH/EmYSQEREwuJ0ABEREZWq0NBQtGzZEpUqVYKdnR169eqFxMRErT7Z2dkICAiAra0tKlasiD59+iA1NVWrT1JSEnx9fVGhQgXY2dlhwoQJePz4sc5xMAkgIiJhKfR4lER0dDQCAgJw7NgxREZGIi8vD507d0ZmZqamz9ixY7Fz505s2bIF0dHRuHnzJnr37q05n5+fD19fX+Tm5uLo0aOIiIhAeHg4pk2bpvv7lyRJKmHsb7ysPLkjIDK8R7m6Z/tEZZWtuWFnrX+JT9HbWF3qWSMnJ0erTaVSQaVSvfS1t2/fhp2dHaKjo9GmTRukp6ejSpUq2LhxIz744AMAwIULF+Di4oKYmBh4eHjgjz/+QLdu3XDz5k3Y29sDAFauXIlJkybh9u3bMDU1fel1WQkgIiLSg9DQUFhaWmodoaGhOr02PT0dAGBjYwMAiI2NRV5eHry9vTV9GjRogJo1ayImJgYAEBMTAzc3N00CAAA+Pj7IyMjAuXPndLouFwYSEZGwlHq8XVBwcDCCgoK02nSpAhQUFGDMmDHw8vJCo0aNAAApKSkwNTWFlZWVVl97e3ukpKRo+jybADw9//ScLpgEEBGRsPS5OUDX0v/zAgICcPbsWRw+fFh/weiI0wFEREQyCQwMxK5du3DgwAFUr15d0+7g4IDc3FykpaVp9U9NTYWDg4Omz/O7BZ5+/bTPyzAJICIiYSn0+L+SkCQJgYGB2L59O/bv3w9nZ2et882bN4eJiQmioqI0bYmJiUhKSoKnpycAwNPTE/Hx8bh165amT2RkJCwsLODq6qpTHJwOICIiYcl1r6CAgABs3LgRv/zyCypVqqSZw7e0tIRarYalpSWGDh2KoKAg2NjYwMLCAp9//jk8PT3h4eEBAOjcuTNcXV0xYMAAhIWFISUlBVOmTEFAQIDO0xLcIkhURnGLIInA0FsEfz936+WddPReQzud+xZ3p8K1a9di0KBBAJ7cLGjcuHHYtGkTcnJy4OPjg+XLl2uV+v/55x+MGjUKBw8ehLm5Ofz9/TFnzhwYG+v2ub1RScDTUF73No5MAkgETAJIBIZOAnafu623sbo0rKK3sUrLG7Em4IcffoCbmxvUajXUajUaN26MdevWyR0WERGVcwqF/o6ySPY1AQsWLMDUqVMRGBgILy8vAMDhw4fx6aef4s6dOxg7dqzMERIREZVPsk8HODs7Y8aMGRg4cKBWe0REBEJCQnDt2rUSj8npABIBpwNIBIaeDtiboL/pgM4uZW86QPZKQHJyMlq3bl2ovXXr1khOTpYhIiIiEkVJt/aVN7KvCahTpw42b95cqP2nn35C3bp1ZYiIiIhIDLJXAmbMmIGPPvoIhw4d0qwJOHLkCKKioopMDoiIiPRFKXYhQP4koE+fPjh+/DgWLlyIHTt2AABcXFxw4sQJuLu7yxscERGVa6JPB8i+MNAQuDCQRMCFgSQCQy8M3H/hrt7G6tDAVm9jlRbZKwG///47jIyM4OPjo9W+Z88eFBQUoGvXrjJFRkRE5V1Z3d+vL7IvDJw8eTLy8/MLtUuShMmTJ8sQERERiUKuBwi9KWRPAi5dulTk044aNGiAy5cvyxARERGRGGRPAiwtLXH16tVC7ZcvX4a5ubkMERERkSiUCv0dZZHsSUDPnj0xZswYXLlyRdN2+fJljBs3Dj169JAxMiIiKu84HSCzsLAwmJubo0GDBnB2doazszNcXFxga2uLb775Ru7w6Bmxf53E6IBP0an9O2jaqD72R+0rtu9XM6ahaaP6WL8uvPQCJNKzH9auRutmDbFoXmihc5IkIShwJFo3a4joA1EyREf0+mTfHWBpaYmjR48iMjISp0+f1jxFsE2bNnKHRs/JynqEevXro9f7fRA0JrDYfvv3ReLMmdOoYqf7s7WJ3jTnz8Xjl5+3oE7dekWe/2nDD6/92HOSn+j/F8qeBACAQqFA586d0blzZ7lDoRd45922eOfdti/sk5qaijmhs7D8uzX4/LORpRQZkX49epSJGf83CZOnzkD4f74rdP5iYgI2rY/A9+t/QvfO7Uo/QNIbwXMAeZKAJUuWYMSIETAzM8OSJUte2Hf06NGlFBW9roKCAkwJngD/QUNRpw6f+0Bl1/w5X6H1O23QspVnoSQgOysLIV9OxLjJU2Bbuew9NY7oWbIkAQsXLoSfnx/MzMywcOHCYvspFIqXJgE5OTnIycnRaitQqqBSqfQSK+lu7ZrVMDIyRv9PBr68M9EbKnLP70i8kIA1634q8vzi+XPh1sQdbdp1KOXIyBCUgs8HyJIEXLt2rch/v4rQ0FDMmDFDq+3LKdMxZVrIa41LJXP+3FlsXP8DNm3ZxnlSKrNSU5KxaN4cLF6+usg/JP6M3o/Yk8cRvmmrDNGRIYj+XyvZnx0wc+ZMjB8/HhUqVNBqz8rKwrx58zBt2rQXvp6VAHk0bVQfCxYvQ4eO3gCA9evCMT9sDpTK/204yc/Ph1KphL1DVfyxd79coZZbfHaA/kUfiELwuNEwMjLStOXn50OhUECpVOL9Dz7Cz5s3Ffl93sS9OZatDpch6vLN0M8OOHY5TW9jedSx0ttYpUX2JMDIyAjJycmwe24l+d27d2FnZ1fkLYVfhg8QMrznk4C0tPu4c/u2Vp9RI4eiW/ee6NmrN2o515YjzHKNSYD+ZWZmIiX5plbb1yH/B6datfHJoKGwsrJCWlqa1vkBfXthzIRgvNOmHRyrVS/FaMVg8CTgSprexvJ4y0pvY5UW2XcHSJJUZPn49OnTsLGxkSEiKs6jR5lISkrSfP3vvzdw4UICLC0tUbWqI6ysrLX6GxubwLZyZSYAVGaYm5vjrecWtarVFWBpaalpL2oxoL1DVSYAZVRZvcmPvsiWBFhbW0OhUEChUKBevXpaiUB+fj4ePnyITz/9VK7wqAjnzp7F8CH/W/Q3P+zJDVS693wfs76eI1dYRET0imSbDoiIiIAkSRgyZAgWLVoES0tLzTlTU1PUqlULnp6erzQ2pwNIBJwOIBEYejrgxNV0vY31dm3Ll3d6w5R6JSA6Ohpvv/02/P39AQDOzs5o3bo1TExMSjsUIiISnNiTATI8OyAxMRHt27fH3bt3AQDu7u7IyspCRkZGkQcREREZRqlXAkaMGAEAaNeuHeLj42FlZVXkwsCnCwZfZXcAERGRTgQvBciyMHDEiBFwd3cHABw4cECOEIiIiLg7QK4Lt2zZEo8fP0Z0dDSGDBmC6tW5vYaIiKg0lfqagGcZGxtj3rx5ePyYq5yJiKj0KRT6O8oiWZMAAOjQoQOio6PlDoOIiEg4st8xsGvXrpg8eTLi4+PRvHlzmJuba53v0aOHTJEREVF5V0b/gNcb2Z8d8OyDOJ73qrsDeLMgEgFvFkQiMPTNgv7+R39b0Zs5WehtrNIieyWgoKBA7hCIiIiEJNuagP3798PV1bXIGwKlp6ejYcOG+PPPP2WIjIiIRKHQ4//KItmSgEWLFmH48OGwsChcPrG0tMTIkSOxYMECGSIjIiJRcHeATE6fPo0uXboUe75z586IjY0txYiIiIjEItuagNTU1Bc+NMjY2Bi3b98uxYiIiEg0ZfQPeL2RrRJQrVo1nD17ttjzZ86cQdWqVUsxIiIiEo5Cj0cZJFsS8N5772Hq1KnIzs4udC4rKwvTp09Ht27dZIiMiIhIDLLdJyA1NRXNmjWDkZERAgMDUb9+fQDAhQsXsGzZMuTn5+Pvv/+Gvb19icfmfQJIBLxPAInA0PcJOPPfh3obq3GNinobq7TIerOgf/75B6NGjcKePXvwNAyFQgEfHx8sW7YMzs7OrzQukwASAZMAEoGhk4D4G/pLAtyqMwl4Jffv38fly5chSRLq1q0La2vr1xqPSQCJgEkAiYBJgGHJfsdAALC2tkbLli3lDoOIiARTRtfz6c0bkQQQERHJQvAsQPZHCRMREZE8WAkgIiJhldV7/usLkwAiIhJWWb3nv75wOoCIiEhQrAQQEZGwBC8EMAkgIiKBCZ4FcDqAiIhIUKwEEBGRsETfHcBKABERCUuh0N9REocOHUL37t3h6OgIhUKBHTt2aJ2XJAnTpk1D1apVoVar4e3tjUuXLmn1uXfvHvz8/GBhYQErKysMHToUDx+W7DbITAKIiIhKWWZmJpo0aYJly5YVeT4sLAxLlizBypUrcfz4cZibm8PHxwfZ2dmaPn5+fjh37hwiIyOxa9cuHDp0CCNGjChRHG/EA4T0jQ8QIhHwAUIkAkM/QOhiyiO9jVXPocIrvU6hUGD79u3o1asXgCdVAEdHR4wbNw7jx48HAKSnp8Pe3h7h4eHo168fEhIS4OrqipMnT6JFixYAgN27d+O9997DjRs34OjoqNO1WQkgIiJxKfR35OTkICMjQ+vIyckpcUjXrl1DSkoKvL29NW2WlpZo1aoVYmJiAAAxMTGwsrLSJAAA4O3tDaVSiePHj+t8LSYBREREehAaGgpLS0utIzQ0tMTjpKSkAADs7e212u3t7TXnUlJSYGdnp3Xe2NgYNjY2mj664O4AIiISlj53BwQHByMoKEirTaVS6W18Q2ASQEREwtLnswNUKpVefuk7ODgAAFJTU1G1alVNe2pqKpo2barpc+vWLa3XPX78GPfu3dO8XhecDiAiInqDODs7w8HBAVFRUZq2jIwMHD9+HJ6engAAT09PpKWlITY2VtNn//79KCgoQKtWrXS+FisBREQkLLluFfTw4UNcvnxZ8/W1a9cQFxcHGxsb1KxZE2PGjMFXX32FunXrwtnZGVOnToWjo6NmB4GLiwu6dOmC4cOHY+XKlcjLy0NgYCD69eun884AgFsEicosbhEkERh6i+CV21l6G+utKmqd+x48eBDt27cv1O7v74/w8HBIkoTp06dj1apVSEtLwzvvvIPly5ejXr16mr737t1DYGAgdu7cCaVSiT59+mDJkiWoWLGiznEwCSAqo5gEkAjKaxLwpuB0ABERCUv0ZwcwCSAiImHpc3dAWcTdAURERIJiJYCIiIQleCGASQAREQlM8CyA0wFERESCYiWAiIiExd0BREREguLuACIiIhISKwFERCQswQsBTAKIiEhcnA4gIiIiIbESQEREAhO7FMAkgIiIhMXpACIiIhISKwFERCQswQsBTAKIiEhcnA4gIiIiIbESQEREwuKzA4iIiEQldg7A6QAiIiJRsRJARETCErwQwCSAiIjExd0BREREJCRWAoiISFjcHUBERCQqsXMATgcQERGJipUAIiISluCFACYBREQkLu4OICIiIiGxEkBERMLi7gAiIiJBcTqAiIiIhMQkgIiISFCcDiAiImFxOoCIiIiExEoAEREJi7sDiIiIBMXpACIiIhISKwFERCQswQsBTAKIiEhggmcBnA4gIiISFCsBREQkLO4OICIiEhR3BxAREZGQWAkgIiJhCV4IYBJAREQCEzwL4HQAERGRoFgJICIiYXF3ABERkaC4O4CIiIiEpJAkSZI7CCrbcnJyEBoaiuDgYKhUKrnDITIIfp9TecQkgF5bRkYGLC0tkZ6eDgsLC7nDITIIfp9TecTpACIiIkExCSAiIhIUkwAiIiJBMQmg16ZSqTB9+nQulqJyjd/nVB5xYSAREZGgWAkgIiISFJMAIiIiQTEJIIPbs2cP1q5dK3cYRCX23Xff4cCBA3KHQWQwTALIoE6fPo1hw4bBw8Oj2D6DBg1Cr169Si8oIh2sWrUKa9aswdtvv11sn1q1amHRokWlFxSRnjEJKAcGDRoEhUKBOXPmaLXv2LEDCj08HSM3NxdhYWFo0qQJKlSogMqVK8PLywtr165FXl5esa+7f/8+/Pz88OOPP8LFxQXXr1+HQqFAXFycVr/FixcjPDz8teMkKkpKSgo+//xz1K5dGyqVCjVq1ED37t0RFRVV7GtOnDiBxYsXY9euXTA3N0d4eDisrKwK9Tt58iRGjBhhwOiJDItPESwnzMzMMHfuXIwcORLW1tZ6Gzc3Nxc+Pj44ffo0Zs2aBS8vL1hYWODYsWP45ptv4O7ujqZNmxb5Omtra5w9e/al17C0tNRbvETPun79Ory8vGBlZYV58+bBzc0NeXl52LNnDwICAnDhwoVCr8nLy8Pbb7+Nc+fOvXT8KlWqGCJsotIjUZnn7+8vdevWTWrQoIE0YcIETfv27dul5/8v3rp1q+Tq6iqZmppKTk5O0jfffPPCsefOnSsplUrp77//LnQuNzdXevjwoSRJktS2bVspICBA+uKLLyRbW1upXbt2kiRJEgBp+/btmn8/e7Rt21YTf8+ePTXj5ufnS3PnzpXeeustydTUVKpRo4b01Vdfac6fOXNGat++vWRmZibZ2NhIw4cPlx48eKDz50Xi6Nq1q1StWjXN9+mz7t+/L0nSk+/L5cuXS927d5cqVKggTZ8+XTpw4IAEQLp//77m388e06dPlyRJkpycnKSFCxdqjTlixAjJzs5OUqlUUsOGDaWdO3dqzpf054/I0DgdUE4YGRlh9uzZWLp0KW7cuFFkn9jYWPTt2xf9+vVDfHw8QkJCMHXq1BeW4jds2ABvb2+4u7sXOmdiYgJzc3PN1xERETA1NcWRI0ewcuXKQv1PnDgBANi3bx+Sk5Oxbdu2Iq8ZHByMOXPmYOrUqTh//jw2btwIe3t7AEBmZiZ8fHxgbW2NkydPYsuWLdi3bx8CAwOLfQ8kpnv37mH37t0ICAjQ+j596tnyfkhICN5//33Ex8djyJAhWv1at26NRYsWwcLCAsnJyUhOTsb48eMLjVdQUICuXbviyJEjWL9+Pc6fP485c+bAyMgIwKv9/BEZnNxZCL2+Z/+S9vDwkIYMGSJJUuFKQP/+/aVOnTppvXbChAmSq6trsWOr1Wpp9OjRL42hbdu2kru7e6F2PFMJuHbtmgRAOnXqVLHxZ2RkSCqVSlq9enWR11m1apVkbW2t9Zfdb7/9JimVSiklJeWlcZI4jh8/LgGQtm3b9sJ+AKQxY8ZotT1bCZAkSVq7dq1kaWlZ6LXPVgL27NkjKZVKKTExscjrvMrPH5GhsRJQzsydOxcRERFISEgodC4hIQFeXl5abV5eXrh06RLy8/OLHE8qwQ0lmzdvXrJgi5CQkICcnBx07Nix2PNNmjTR+svOy8sLBQUFSExMfO3rU/lRku/dFi1avPb14uLiUL16ddSrV6/I86/y80dkaEwCypk2bdrAx8cHwcHBehmvXr16RS6eKkpRJdeSUqvVrz0GEQDUrVsXCoVCp+9ffu+SqJgElENz5szBzp07ERMTo9Xu4uKCI0eOaLUdOXIE9erV08xbPq9///7Yt28fTp06VehcXl4eMjMzdY7L1NQUAF74V0/dunWhVquL3b7l4uKC06dPa133yJEjUCqVqF+/vs6xUPlnY2MDHx8fLFu2rMjv07S0NJ3HMjU1felf640bN8aNGzdw8eLFIs+/ys8fkaExCSiH3Nzc4OfnhyVLlmi1jxs3DlFRUZg1axYuXryIiIgIfPvtt0UucnpqzJgx8PLyQseOHbFs2TKcPn0aV69exebNm+Hh4YFLly7pHJednR3UajV2796N1NRUpKenF+pjZmaGSZMmYeLEifjhhx9w5coVHDt2DGvWrAEA+Pn5wczMDP7+/jh79iwOHDiAzz//HAMGDNAsHiR6atmyZcjPz8fbb7+Nn3/+GZcuXUJCQgKWLFkCT09PncepVasWHj58iKioKNy5cwePHj0q1Kdt27Zo06YN+vTpg8jISFy7dg1//PEHdu/eDeDVfv6IDE7uRQn0+p7fYidJTxbhmZqaFrtF0MTERKpZs6Y0b968l46fnZ0thYaGSm5ubppteV5eXlJ4eLiUl5cnSdKThYFffPFFodfimYWBkiRJq1evlmrUqCEplcoXbhH86quvJCcnJ02cs2fP1pznFkEqiZs3b0oBAQGSk5OTZGpqKlWrVk3q0aOHdODAAUmSCn+PSlLhhYGSJEmffvqpZGtr+8Itgnfv3pUGDx4s2draSmZmZlKjRo2kXbt2ac6/ys8fkSHxUcJERESC4nQAERGRoJgEEBERCYpJABERkaCYBBAREQmKSQAREZGgmAQQEREJikkAERGRoJgEEBERCYpJAFEZMGjQIPTq1Uvzdbt27TBmzJhSj+PgwYNQKBQluu8+Eb25mAQQvYZBgwZBoVBAoVDA1NQUderUwcyZM/H48WODXnfbtm2YNWuWTn35i5uIimMsdwBEZV2XLl2wdu1a5OTk4Pfff0dAQABMTEwKPc45NzdX8yTF12VjY6OXcYhIbKwEEL0mlUoFBwcHODk5YdSoUfD29savv/6qKeF//fXXcHR01Dzq+L///S/69u0LKysr2NjYoGfPnrh+/bpmvPz8fAQFBcHKygq2traYOHEinn/Ex/PTATk5OZg0aRJq1KgBlUqFOnXqYM2aNbh+/Trat28PALC2toZCocCgQYMAAAUFBQgNDYWzszPUajWaNGmCrVu3al3n999/R7169aBWq9G+fXutOImo7GMSQKRnarUaubm5AICoqCgkJiYiMjISu3btQl5eHnx8fFCpUiX8+eefOHLkCCpWrIguXbpoXjN//nyEh4fj+++/x+HDh3Hv3j1s3779hdccOHAgNm3ahCVLliAhIQHfffcdKlasiBo1auDnn38GACQmJiI5ORmLFy8GAISGhuKHH37AypUrce7cOYwdOxaffPIJoqOjATxJVnr37o3u3bsjLi4Ow4YNw+TJkw31sRGRHGR+iiFRmfbsY5ALCgqkyMhISaVSSePHj5f8/f0le3t7KScnR9N/3bp1Uv369aWCggJNW05OjqRWq6U9e/ZIkiRJVatWlcLCwjTn8/LypOrVq2s9bvnZRzcnJiZKAKTIyMgiYyzqsbjZ2dlShQoVpKNHj2r1HTp0qPTxxx9LkiRJwcHBkqurq9b5SZMmFRqLiMourgkgek27du1CxYoVkZeXh4KCAvTv3x8hISEICAiAm5ub1jqA06dP4/Lly6hUqZLWGNnZ2bhy5QrS09ORnJyMVq1aac4ZGxujRYsWhaYEnoqLi4ORkRHatm2rc8yXL1/Go0eP0KlTJ6323NxcuLu7AwASEhK04gAAT09Pna9BRG8+JgFEr6l9+/ZYsWIFTE1N4ejoCGPj//1YmZuba/V9+PAhmjdvjg0bNhQap0qVKq90fbVaXeLXPHz4EADw22+/oVq1alrnVCrVK8VBRGUPkwCi12Rubo46dero1LdZs2b46aefYGdnBwsLiyL7VK1aFcePH0ebNm0AAI8fP0ZsbCyaNWtWZH83NzcUFBQgOjoa3t7ehc4/rUTk5+dr2lxdXaFSqZCUlFRsBcHFxQW//vqrVtuxY8de/iaJqMzgwkCiUuTn54fKlSujZ8+e+PPPP3Ht2jUcPHgQo0ePxo0bNwAAX3zxBebMmYMdO3bgwoUL+Oyzz164x79WrVrw9/fHkCFDsGPHDs2YmzdvBgA4OTlBoVBg165duH37Nh4+fIhKlSph/PjxGDt2LCIiInDlyhX8/fffWLp0KSIiIgAAn376KS5duoQJEyYgMTERGzduRHh4uKE/IiIqRUwCiEpRhQoVcOjQIdSsWRO9e/eGi4sLhg4diuzsbE1lYNy4cRgwYAD8/f3h6emJSpUq4f3333/huCtWrMAHH3yAzz77DA0aNMDw4cORmZkJAKhWrRpmzJiByZMnw97eHoGBgQCAWbNmYerUqQgNDYWLiwu6dOmC3377Dc7OzgCAmjVr4ueff8aOHTvQpEkTrFy5ErNnzzbgp0NEpU0hFbfaiIiIiMo1VgKIiIgExSSAiIhIUEwCiIiIBMUkgIiISFBMAoiIiATFJICIiEhQTAKIiIgExSSAiIhIUEwCiIiIBMUkgIiISFBMAoiIiAT1/wBuhHyreSb4RwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(df_test['etiqueta'], df_test['predicted'])\n",
        "\n",
        "# Optional: define class labels (adjust to your problem)\n",
        "labels = ['No Crítico', 'Crítico']  # 0 = No crítico, 1 = Crítico\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
